# 2장 개략적인 규모 추정

시스템을 설계하기 위해 개략적 규모 추정을 어떻게 수행할지에 대하여 정리한다.

## 2의 제곱수

분산 시스템에서의 기본적인 계산법은 2의 제곱수의 단위로 표현된다.

일단 데이터의 단위를 알아야 한다.

- 1bit
- 1byte (8비트) -> ASCII문자 하나가 1바이트
- 1kb = 1024byte
- 1mb = 1024kb
- 1gb = 1024mb
- 1tb = 1024gb

1024 == 2의 10승

## 모든 프로그래머가 알아야 하는 레이턴시(latency)

2010년에 구글의 제프 딘이 발표한 응답 지연시간 들이다.

|연산명|시간|
|---|---|
|L1캐시 참조|0.5ns|
|뮤젝스 락/언락|100ns|
|주 메모리 참조|100ns|
|1Gbps네트워크로 2Kb전송|20,000ns = 10us|
|메모리에서 1MB순차적으로 READ|250,000ns = 250us|
|디스크 탐색|10,000,000ns = 10ms|
|네트워크에서 순차적으로 1MB read|10,000,000nx = 10ms|
|디스크에서 1MB 순차적으로 read|30,000,000ns = 30ms|

대략적인 수치들이 이렇다 정도로만 알고 가자.

위의 값들로 알 수 있는건 다음과 같다.

- 메모리는 빠르지만 디스크는 느리다. (위의 표는 HDD)
- 디스크 탐색은 피하라.(SSD의 경우 문제 X)
- 단순한 압축 알고리즘은 빠르다.
- 데이터를 네트워크에 보내기전에 가능하면 압축하라.(Kafka Message 압축)

## 가용성에 관계된 수치들

고가용성이란 시스템이 오랜 시간동안 중단 없이 운영될 수 있는 능력을 지칭한다. 고가용성이 100%라면 한 번도 중단된 적 없는 서비스를 의미한다.

구글, 아마존, 마이크로소프트의 경우는 보통 99% 이상의 고가용성을 제공한다. 9가 많으면 많을 수록 좋은 편

## 예제: 트위터 QPS(Query Per Second)와 저장소 요구량 추정

가정은 다음과 같다.

- MMU : 3억명
- 50% 사용자가 매일 트위터 사용
- 각 사용자는 2건의 트윗을 매일 올림
- 미디어를 포함하는 트윗 10%
- 데이터는 5년간 보관

추정은 다음과 같다.

- 일간 능동 사용자 : 3억 * 50% = 1.5억명
- QPS : 1.5억 * 2트윗/24시간/3600초 = 약 3500
- 최대 QPS : QPS * 2 = 7000

미디어 저장을 위한 저장소 요구량

- 평균 트윗 크기
   - tweet_id : 64바이트
   - 텍스트 : 140바이트
   - 미디어 : 1MB
- 미디어 저장소 요구량 : 1.5억명 * 2 * 10% * 1MB = 30TB/일
- 5년간 미디어 저장을 위한 요구량 : 30TB * 365 * 5 = 55PB

---

## 필자의 팁

- 우리는 정확한 값을 계산하는게 아니다. 생각하는 과정을 보는 것이기 때문에 계산을 정확히 하지 마라.
- 단위를 붙여라 : kb, mb, per/s 등 단위를 붙여라
- QPS, 저장소 요구량, 캐시 요구량, 서버 수 등을 추정하는 문제가 많이 나온다. 이들에 대해 미리 연습하라.

# 3장 시스템 설계 면접 공략법

시스템 설계 면접은 결과도 정답도 없다. 그냥 최종적으로 도출할 설계안에 당신의 생각과 논리를 모두 담으면 된다. 

_면접 팁들을 정리해 주는데 이는 면접볼 때 다시 책을 한번 읽기_

# 4장 처리율 제한 장치의 구현

처리율 제한 장치는 클라이언트 또는 서비스가 보내는 트래픽의 처리율을 제어하기 위한 장치이다. 

- 사용자는 초당 2회 이상 새 글을 올릴 수 없다.
- 같은 IP주소로는 하루에 10개 이상의 계정을 생성할 수 없다.
- 같은 디바이스로는 주당 5회 이상 리워드를 요청할 수 없다.

등등 대규모 서비스는 이러한 처리율 제한 장치가 필수적으로 필요하다. 

처리율 제한을 통한 장점은 무엇일까?

- DoS 공격 예방
- 비용 절감
- 서버 과부화 막기

## 처리율 제한을 하는 방법

1. 클라이언트에서 API요청을 제한한다.
	-> 클라이언트는 쉽게 위변조될 수 있으며 모든 클라이언트에 해당 작업을 구현하기는 쉽지 않다.

2. 서버에서 구현한다.
	-> 서버에서 공통 로직을 두는 것이 권장된다. 정 안되면 미들웨어를 둬라.
    
> HTTP상태 코드 429를 활용하라.(Too many requests)

- 마이크로서비스의 경우 처리율 제한을 위해 미들웨어로 `API 게이트웨이`(미들웨어)를 활용한다. 

- 각각의 Service마다 어플리케이션단에서 처리율 제한을 직접 구현할 수 있다.

## 처리율 제한 알고리즘

### 토큰 버킷

가장 널리 사용되는 알고리즘으로 아마존과 스트라이프가 API요청을 통제하기 위해 사용한다. 원리는 다음과 같다.

1. 버킷이 있고, 해당 버킷 내부에는 사전 설정된 양의 토큰이 주기적으로 채워진다.
2. 토큰 공급기는 매초 2개의 토큰을 추가한다.
3. 버킷이 가득차면 추가된 토큰은 버려진다.
4. 각 요청마다 하나의 토큰을 사용한다.
4-1. 토큰이 없을 경우 요청은 버려진다.

![](https://velog.velcdn.com/images/cksgodl/post/a7a1daf7-6325-467d-98aa-3be2e4a871f8/image.png)

토큰을 할당하기 위해서 IP주소, 유저 아이디, 쿠키 값에 따라 버킷을 제한할 수 있다. 상황에 맞추어 설정하자.

#### 장점
- 구현이 쉽다.
- 메모리 사용 측면에서 효율적이다??
- 짧은 시간에 집중되는 트래픽을 처리 가능하다.

#### 단점
- 값을 튜닝하기 어렵다.

> 블로그글을 쓰고 있는 본인의 생각은 `이게 k8s환경에서 가능할까?`이다. 인스턴트가 여러개 뛰어지면 로드밸런서에 의해서 어플리케이션단의 토큰 버킷알고리즘은 무용지물이다.

__어플리케이션단의 토큰 버킷알고리즘을 제공하기 위해 레디스와 같은 캐시 DB를 활용한다?__

__로드 밸런서단에서 토큰 버킷알고리즘을 적용한다는게 가능한가?__에 대해 생각을 해 보았을 때 이는 불가능하고 k8s환경에서는 다음과 같은 방법을 쓸 수 있다.

- 포드에 대한 리소스 제한 설정

- Horizontal Pod Autoscaling (HPA)
   - Http Request에 따른 HPA활용

- 커스텀 제어러나 사이드카 패턴 사용
   - 특별한 상황에서는 커스텀 제어러나 사이드카를 활용하여 특정 작업을 수행하도록 조정할 수 있다.

_책에서는 위의 내용까지는 알려주지 않아서 아쉽다._

### 누출 버킷

`FIFO`큐를 활용해 버킷 알고리즘을 구현하지만, 요청 처리율이 고정되어 있다.

1. 요청이 도착하면 큐가 가득 차 있는지 본다. 빈자리가 있는 경우에는 큐에 요청을 추가한다.
2. 큐가 가득 차 있는 경우 새 요청은 버린다.
3. 지정된 시간마다 큐에서 요청을 꺼내어 처리한다.

#### 장점

- 큐의 크기가 제한되어 있어 메모리 사용량 측면에서 효율적
- 고정된 처리율을 갖고 있기에 안정적 출력이 필요한 경우 적합

#### 단점

- 단시간에 트래픽이 몰리는 경우 큐에는 오래된 요청들이 쌓이게 된다. (최신 요청이 버려짐)
- 튜닝이 힘들다.

### 고정윈도 카운터

동작 과정은 다음과 같다.

1. 타임라인을 고정된 간격 윈도로 나누고, 각 윈도마다 카운터를 붙인다.
2. 요청이 접수될 떄마다 이 카운터의 값은 1씩 증가한다.
3. 카운터의 값이 사전에 설계된 임계치에 도달하면 새 요청은 윈도가 열릴 떄 까지 버려진다.

![](https://velog.velcdn.com/images/cksgodl/post/32153eb0-c600-4e14-841a-56844d875c9b/image.png)

많은 트래픽이 윈도 경계 부근에 몰릴 경우 윈도에 할당된 양보다 더 많은 요청이 처리도리 수 있다.

#### 장점

- 메모리 효율이 좋다.
- 이해하기 쉽다.

#### 단점

- 윈도 경계 부근에서 일시적으로 많은 트래픽이 몰려드는 경우, 기대했던 시스템의 처리 한도보다 많은 양의 요청을 처리하게 된다.

### 이동 윈도 로그

고정 윈도 카운터 알고리즘은 경계부근에 트래픽이 집중될 때 설정된 한도보다 많은 요청을 처리하게 된다. 이동 윈도 로그 알고리즘은 이 문제를 해결한다.

1. 요청의 타임스탬프를 추적한다. 타임스탬프는 보통 레디스의 정렬 집합 같은 캐시에 보관한다.
2. 새 요청이 오면 만료된 타임스탬프는 제거한다.
3. 새 요청의 타임스탬프를 로그에 추가한다.
4. 로그의 크기가 허용치보다 같거나 작으면 요청을 시스템에 전달한다. 그렇지 않은 경우 처리를 거부한다.
![](https://velog.velcdn.com/images/cksgodl/post/9016d76f-2800-49ac-a825-271ce0831265/image.png)

#### 장점

- 메커니즘이 아주 정교하여, 허용 요청의 개수가 처리율 한도를 넘지 않는다.

#### 단점

- 다량의 메모리를 사용한다. (거부된 타임스탬프도 보관하기 때문)

### 이동 윈도 카운터

![](https://velog.velcdn.com/images/cksgodl/post/0576948e-bb30-4721-a668-80af3ce59bed/image.png)

분당 7개의 요청을 처리할 수 있을 때 새요청이 온 경우 1분의 30 시점에서 도착한 새 요청의 경우 현재 윈도에 몇 개의 요청이 온것으로 보고 처리해야할까?

- 현재 1분간의 요청 수 + 직전 1분간의 요청 수 * 이동 윈도와 직전 1분이 겹치는 비율
- 이공식에 따르면 위의 사진에서 3+5*0.7 = 6.5개이다.

본 예제의 경우 처리율 제한 한도가 분당 7개 요청이라고 했으므로, 현재 1분의 30% 시점에 도착한 신규 요청은 시스템으로 전달될 것이다. 하지만 그 이후의 요청은 한계에 도달하였으므로, 더 이상의 요청은 받을 수 없다.

#### 장점

- 이전 시간대의 평균 처리율에 따라 현재 윈도의 상태를 계산하므로, 짧은 시간에 몰리는 트래픽에 대응할 수 있다.
- 메모리 효율이 좋다.

#### 단점

- 직전 시간대에 도착한 요청이 균등하게 분포되어 있다고 가정한 상태에서 추정치를 계산하기에 다소 느슨하다.

## 개략적인 아키텍처

처리율 제한 알고리즘의 기본 아이디어는 단순하다. 하지만 이런 처리에 대한 값을 어디에 저장해야 할까??

__바람직한 것은 메모리상에서 동작하는 캐시 또는 데이터 베이스이다.__ 디스크 기반 데이터베이스는 디스크 접근 때문에 느리니까 사용하면 안된다. 

대표적인 메모리 기반 데이터베이스 레디스는 다음과 같은 두 명령어를 지원한다.

- INCR: 메모리에 저장된 카운터의 값을 1만큼 증가시킨다.
- EXPIRE: 카운터에 타임아웃 값을 설정한다. 설정된 시간이 지나면 카운터는 삭제된다.

위의 두 명령어 모두 처리율 제한 알고리즘에 쓰일 수 있다.

---


#### HTTP 헤더를 통한 처리율 제한

클라이언트는 자신의 요청이 처리율 제한에 걸리고 있는지를 HTTP 응답헤더를 통해 알 수 있다.

- X-Ratelimit-Remaining : 윈도 내에 남은 처리 요청의 수
- X-Ratelimit_Limit : 매 윈도마다 클라이언트가 전송할 수 있는 요청의 수
- X-Ratelimit-REtry-After : 한도 제한에 걸리지 않으려면 몇 초 뒤에 요청을 다시 보내야 하는지 알림

사용자가 너무 많은 요청을 보내면 429 `too many requests` 오류를 `X-Ratelimit-Retry-After` 헤더와 함께 반환하도록 한다.


## 분산 환경에서의 처리율 제한

분산 환경에서는 두 가지 문제가 나타난다.

1. 경쟁 조건
2. 동기화

### 경쟁 조건

레디스와 같은 데이터베이스에서는 경쟁 조건이 발생할 수 있다. 따라서 레디스는 두가지 해결 방법을 제공한다.

- 루아 스크립트
- 정렬 집합(sorted set)

### 동기화 이슈

처리율 제한 장치가 여러개라면 클라이언트마다 다른 처리율 제한을 할 수 있다. 

1. 스티키 세션을 통해 같은 클라이언트로부터 요청은 항상 같은 처리율 제한장치로 보낼 수 있도록 할 수 있다. (비추천)
2. 레디스와 같은 데이터베이스 활용

## 요약

- 처리율 제한 알고리즘을 기억하라.
  - 토큰 버킷
  - 누출 버킷
  - 고정 윈도 카운터
  - 이동 윈도 로그
  - 이동 윈도 카운터

- 처리율 데이터 저장 데이터베이스
- 분산환경에서의 처리율 제한 방법에 대하여
- 처리율 제한을 회피하는 방법, 클라이언트를 설계하는 방법
  - 클라이언트 캐시를 활용하여 API 호출 횟수를 줄인다.
  - 쓰로틀링을 구현한다.(리트라이 로직에 백오프 시간 추가)
  - 오류를 클라이언트가 우아하게 복구한다.
  
  

