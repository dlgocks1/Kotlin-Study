# 안정 해시 설계

## 해시 키 재배치(rehash) 문제

해시를 계산하는 모듈러 연산의 경우 (ex: hash(key0) % 4) 값을 분산시키기 위해 많이 사용된다.

로드밸런서에 해당 알고리즘을 활용할 때 만약 서버 풀의 크기가 고정되어 있을 때는 잘 동작하나, 서버가 늘어나거나 줄어들면 서버 인덱스 값이 줄어들기에 해시 키를 재배치 해야한다.

> 실제로는 로드밸런서에 해시 키 재배치를 사용하는 경우는 거의 없다. 라운드 로빈 알고리즘을 활용하기에

이에 따라 안정 해시가 등장하게 되었다.

### 안정 해시

**안정 해시는 해시 테이블 크기가 조정될 떄 평균적으로 오직 `k/n`개의 키만 재배치하는 해시 기술이다.**

이는 아래의 그림과 같이 해시 공간을 링으로 만들어 활용한다.

![](https://velog.velcdn.com/images/cksgodl/post/2625e23b-8b82-4897-a252-4be842194a1a/image.png)

해시키가 서버를 선택하게 되는 과정은 다음과 같다.

1. 해시힘수를 통해 키가 배치된다.
2. 배치된 키는 시계방향으로 가장 가까운 서버를 선택한다.
- 서버를 추가하더라도 키와 가까운 서버만 재배치하면 된다.
- 서버를 제거하더라도 키와 연관된 서버만 삭제하면 된다.


#### 문제점

- 키 사이의 파티션 크기를 균등하게 유지하는 것이 불가능하다.
   - 이를 해결하기위해 가상 노드를 활용할 수 있다. 이는 키사이에 가상의 노드를 넣어 키가 순회하는 과정을 줄이기 위해 사용된다. 하지만 이는 가상 노드 데이터를 저장해야하며, 키가 삭제나 추가될 때 트레이드오프가 발생한다.
     - 키의 재배치에 대하여 : 새로운 서버가 추가될 때 키 뿐만 아니라 가상노드 또한 재배치가 필요하다.
     
## 안정해시 요약

- 서버가 추가되거나 삭제될 떄 재배치되는 키의 수가 최소화된다.
- 데이터가 보다 균등하게 분포하게 된다. 수평적 규모 확장성을 달성할 수 있다.
- 핫스팟 키 문제를 줄인다. 특정한 샤드에 대한 접근이 지나치게 빈번할 경우 활용할 수 있다. Or 라운드로빈 알고리즘이 공평하지 않을 때


# 6장 키-값 저장소 설계

비 관계형 데이터베이스로 `키-값 저장소`를 활용할 수 있따. 이런 키-값 저장소는 몇 가지 장점이있다.

- 특정키에 대하여 O(1)로 접근이 가능하다.
- range search가 힘들다.
   - scan, keys와 같은 레디스 명령어는 결국 풀스캔을 돈다.
- 키 값에 저장되는 데이터 구조를 다양하게 할 수 있다.
- 레디스와 같은 데이터베이스는 메모리 데이터베이스임으로 더 빠르다.


## 분산 키-값 저장소

레디스와같은 메모리 데이터베이스를 활용하기 위해선 수평적 확장이 필수불가결하다. 그러기 위해서 우리는 분산 키-값 저장소가 필요하다.

분산 시스템을 정의할때 `CAP 정리`를 이해하면 좋다.

## CAP 정리

- Consistency (일관성)
   - 모든 클라이언트는 같은 데이터를 보아야 한다.
- Availability (가용성)
   - 분산 시스템에 접속하는 클라이언트는 일부 노드에 장애가 발생하더라도 응답을 받아야 한다.
- Partition Tolerance (파티션 감내)
   - 파티션은 두 노드 사이에 통신 장애가 발생하여도, 시스템은 동작해야 한다.
   
![](https://velog.velcdn.com/images/cksgodl/post/070f6158-63bc-4e17-9ee5-4b1e9539a412/image.png)

이와 같이 CAP모두를 만족할 수는 없다.

실 세계에서는 CA 시스템이 존재하지 않는다. (네트워크 장애는 피할 수 없음으로, 파티션 장애는 있을 수 밖에 없다.)

따라서 CP, AP시스템이 어떻게 설계되는지 알아보자.

### 분산 시스템 컴포넌트

- 데이터 파티션
- 데이터 다중화
- 일관성
- 일관성 불일치 해소
- 장애 처리
- 시스템 아키텍처 다이어그램
- 쓰기 경로
- 읽기 경로

### 데이터 파티션

데이터를 싱글 서버에 넣는것은 불가능하기에 수평적으로 서버를 확장하고, 데이터를 여러 서버에 고르게 분산할 수 있어야 한다.

우리는 위에서 안정 해시를 배웠기에 안정해시 알고리즘을 활용해 데이터 파티션을 올바르게 분할할 수 있다.

> 위의 원형해시 알고리즘에 따르면 각각의 서버는 다른 데이터를 저장하게 된다. 이후에 나올 데이터의 다중화 없이는 서버가 다운되면 그대로 데이터 유실된다.

> 분산 레디스 저장소의 구현체 [`nbase arc`](https://d2.naver.com/helloworld/614607)의 경우도 키 해시 기반의 random partitioning을 기반으로 한다. 이는 각각의 파티션 그룹을 선택할 때 해시 알고리즘을 활용한다. 

![](https://velog.velcdn.com/images/cksgodl/post/bd693700-57ac-4980-a0df-680047ea4b43/image.png)


### 데이터 다중화

데이터를 `N`개의 서버에 비동기적으로 다중화할 필요가 있다. 책에서 필자는 원형해쉬를 순회하며 만나는 첫 N개의 서버에 데이터 사본을 저장한다.

![](https://velog.velcdn.com/images/cksgodl/post/df63f26d-9c12-4901-9062-43ba017a9c32/image.png)

위의 그림에서 N7, N0사이에 할당된 키는 N0, N1, N2에 저장되게 된다.


### 데이터의 일관성

여러 노드에 다중화된 데이터는 적절히 동기화가 되어야한다. 이에 따라 **정족수 합의 프로토콜**을 활용한다.

이는 `ACK`을 활용한 쓰기 기법으로도 알려져있으며, N=3이라면 3개 이상의 노드로 부터 ACK을 받아야 한다.

> 하지만 데이터가 동시에 쓰여질 때 데이터의 비 일관성이 발생할 수도 있기에 이에 따라 데이터에 버전을 붙이는 데이터 버저닝을 활용할 수도 있다. 


### 시스템 아키텍처 다이어그램

이러한 저장되는 노드와 클라이언트와 통신하는 노드를 분리하여 중재자 노드를 만들 수 있다. 이는 게이트웨이라고도 불린다.

![](https://velog.velcdn.com/images/cksgodl/post/941bae4b-c2ac-4323-b309-7ce4051c2d3d/image.png)

> 위는 nbase-arc의 구상도인데 이는복수의 클러스터로 구성되어 있다. 하나의 클러스터는 여러 개의 게이트웨이(gateway)와 복제 그룹으로 이루어져 있고 각 복제 그룹의 단위 저장소를 Redis로 활용한다.


### 쓰기 방식

__카산드라의 경우는 아래와 같은 쓰기 방식을 제공한다.__

![](https://velog.velcdn.com/images/cksgodl/post/c26361f4-1890-4fc2-ac86-b405a4744da5/image.png)

1. 쓰기 요청이 커밋 로그파일에 기록된다.
2. 데이터가 메모리 캐시에 기록된다.
3. 메모리 캐시가 가득차거나, 정의된 임계치에 도달하면 데이터는 SSTable에 기록된다.


__nbase arc의 경우 아래와 같은 쓰기 방식을 제공한다.__

![](https://velog.velcdn.com/images/cksgodl/post/564764cb-e4e1-4c2d-beb6-e97222e370da/image.png)

1. 게이트웨이는 쓰기 요청을 마스터 replicator에 전송한다. (클라이언트 응답 전송)
2. 마스터 replicator은 복제 요청을 직렬화하여 로그 파일로 저장한다. (로그 파일은 모든 슬레이브 replicator에 비동기로 전송된다.)
3. 전송된 로그파일은 일련 번호를 가지고 있기에 저장할지를 이를 통해 판단한다.
4. 로그파일을 통해 Redis에 이를 기록한다.

> 위의 방식으로 nbase arc는 빠른 응답속도와 비동기 복제를 가능하게 한다.


### 읽기 방식

**카산드라의 메모리 읽는 방식은 쓰기 방식과 비슷하다.
**
1. 메모리 캐시 확인
2. 없으면 중간에 블룸필터를 확인한다. (이를 통해 어떤 SSTable에 키가 저장되어있는지 확인)
3. SStable에서 데이터를 가져온다.

**nbase arc의 데이터 읽는 방식도 쓰기 방식과 비슷하다.
**

![](https://velog.velcdn.com/images/cksgodl/post/fccad7fb-c85d-45c7-8272-6e6f1e43cc0e/image.png)

1. `Configuration`을 통해 어떤 클러스터에서 검색할지 지정한다.
2. 해당 클러스터의 로드밸런서를 통해 게이트웨이가 선택된다.
3. 선택된 게이트웨이에서 해싱 키를 통해 파티션 그룹을 선택한다.
4. 선택된 파티션 그룹 내에서 키값에 대한 밸류 읽어온다.


## 요약

|목표, 문제|기술|
|---|---|
|대규모 데이터 저장|안정 해시를 사용해 서버 분산|
|읽기 연산 가용성 보장|데이터를 여러 데이터 센터에 다중화(레플리카)|
|쓰기 연산 가용성 보장|버저닝 및 로그 파일 commit message 활용|
|데이터 파티션|안정 해시|
|점진적 규모 확장성|안정 해시, 클러스터, 다중 게이트웨이|
|조절 가능한 일관성|정족수 합의|
|장애 처리|머클 트리 및 느슨한 정족수 프로토콜 구현|


# 7장 분산 시스템을 위한 유일 ID 생성기 설계

우리가 흔히아는 인덱스는 분산 시스템으로 발전하게 되며 중복이 생겨나게 된다.

따라서 유일 `ID 생성기`가 필요하게 된다. (몽고의 `ObjectID`)

## 개략적인 접근법

유일성이 보장되는 ID를 만드는 방법은 다음과 같은 방법이 있다.

### 다중 마스터 복제

이는 샤딩된 데이터베이스 숫자만큼 값을 더하여 키값을 지정하는 것을 의미한다.

- 1번 데이터베이스 : 1, 3, 5 ...
- 2번 데이터베이스 : 2, 4, 6 ...

이를 통해 유일한 아이디를 만들 수 있지만 다음과 같은 단점이 있다.

- 여러 데이터 센터에 걸쳐 규모를 늘리기 어렵다.
- ID의 유일성은 보장되지만, 그 값이 시간 흐름에 맞추어 커지도록 보장할 수 없다.
- 서버를 추가하거나 삭제할 때도 잘 동작하도록 만들기 어렵다.

### UUID

컴퓨터 시스템에 저장되는 유일한 값을 UUID라고 한다. 이는 128비트 값이며 중복이 거의 발생하지 않는다.

#### 장점 

- UUID를 만드는 것은 단순하다. 서버 사이의 조율이 필요 없다. (동기화 필요 X)
- 각 서버가 쓸 ID를 알아서 만든다. -> 규모확장이 쉽다.

#### 단점

- ID가 128비트로 길다.
- ID를 시간순으로 정렬할 수 없다.
- ID에 숫자가 아닌 값이 포함된다.

대표적인 예로는 몽고DB가 해당 키생성을 활용한다.


### 티켓 서버

중앙에 티켓 서버를 두고 각각의 데이터베이스에서 분산된 키 값을 할당받아 사용하는 방식읻다. 이는 구현하기 쉽지만, SPOF가 발생한다.

### 트위터 스노플레이크 접근법

트위터에서 만든 독창적인 ID생성 기법이다.

이는 64비트 키를 생성하며 키의 구조를 분리하여 키를 저장한다. 키 내부에는

- 잔여비트 (1비트)
- 타임스탬프 (41비트)
- 데이터센터 ID (5비트)
- 서버 ID (5비트)
- 일련번호 (12비트)

로 구성된다. 

타임스탬프가 41비트임으로 Epoch.timemill()로 구성할때 69년을 보장 한다.

> 데이터센터에 따라, 서버 ID에 따라 타임스탬프에 따라 다른 키를 만들어내는 간단하면서도 명료한 접근방법이다. 

## 요약

유일 키를 만드는 방법를 기억하자.

- 다중 마스터 복제
- UUID
- 티켓 서버
- 트위터 스노플레이크

트위터 스노플레이크 기법의 경우 일련번호 비트를 줄이고, 타임 스탬프길이를 늘려 더 오랫동안 저장할 수 있을 것이다.

# 8장 URL 단축기 설계

URL 단축이란 아래와 같은 URL을

```
https://www.wanted.co.kr/wd/174214?utm_source=google&utm_medium=sa&utm_campaign=kr_recruit_web_dsa_apply&utm_term=&utm_content=dsa_ios_developer&gad_source=1
```

아래와 같이 줄이는 것을 의미한다.

```
https://www.wanted.co.kr/wd/174214?4ukgc1saXS
```

아래 URL로 접속하여도 본래의 URL로의 접속이 가능해야 한다. 또한 서버는 URL 리디렉션(서버코드 301)을 통해서 해당 URL로 온 요청을 전달해야 한다.

가장 직관적인 방법은 해시 테이블을 활용하여 해시 테이블에 `<단축 URL, 원래 URL>`의 형태로 저장하여 가져다 쓰는 것이다.

## URL 단축

적절한 해시 함수 fx를 찾되,

- 해시 충돌이 일어나면 안된다.
- 기존 URL로의 복원이 가능해야 한다.

특정 N개의 값을 반환하는 해시 함수는 상황에따라 그 값의 비트 수를 조절할 수 있다. ([0-9, a-z, A,Z]로 구성한다고 가정)

|n|생성 가능 URL갯수|
|---|---|
|1|62**1|
|2|62**2|
|3|62**3|
|7|62**7 == 약 3.5조|


### 해시 충돌 방지

- `CRC32`, `MD5`, `SHA-1`같이 잘 알려진 해시 함수를 이용할 수 있다.

이들은 각각의 알고리즘에 따라 N개의 비트로 결과를 발생시킨다.

- `base-62`변환 활용

이는 62개의 문자를 사용하기에 가능하며, 유일성 보장 ID생성기가 필요하다. 또한 URL의 길이가 가변적이, 다음 URL을 예측할 수 있다.

## URL 리다이렉션

전체적인 흐름도는 다음과 같다.

1. 입력으로 긴 URL을 받는다.
2. 데이터베이스에 해당 URL이 있는지 검사한다.
3. 데이터베이스에 있다면 해당 URL의 값을 반환한다.
4. 없는 경우 단축 URL을 만들고 데이터 베이스에 저장한다.
5. 클라이언트에게 해당 값을 전달한다.

하지만 이런 과정 또한 데이터베이스를 거치기 때문에 로드밸런서의 캐시 기능을 활용해 이를 해결할 수 있다.


