이번장에서는 `JSON`, `XML`, `Thrift`, `Avro`등의 데이터 부호화를 위한 다양한 형식을 알아본다. 특히 스키마를 변경하고 예전 버전과 최신 버전이 어떻게 공존하는지를 설명한다. 

## 데이터 부호화 형식

데이터를 파일에 쓰거나 네트워크를 통해 전송하려면 스스로를 포함한 일련의 바이트열(ex: `JSON`)으로 부호화해야 한다. 이 일련의 바이트열은 보통 메모리에서 사용하는 데이터 구조와는 상당히 다르다.


> 부호화? 직렬화?
>
> __직렬화__는 트랜잭션의 맥락에서 사용된다.(7장) 따라서 책에서는 중복 사용을 피하기 위해 __부호화__를 사용한다.

### 언어별 형식

많은 프로그래밍 언어는 인메모리 객체를 바이트열로 부호화하는 기능을 내장한다.

- Java : Serializable
- Ruby : Marshal
- Python : pickle

프로그래밍 언어에 내장된 부호화 라이브러리는 최소한의 추가 코드로 인메모리 객체를 저장하고 복원할 수 있어 편리하지만 문제점도 많다.

- 특정 프로그래밍 언어로 묶여 있어 다른 언어에서 데이터를 읽기 힘들다.
- 임의의 바이트열을 복호화할 수 있는 어플리케이션이 있으면 임의의 클래스를 인스턴스화 하여 보안에 장애가 생길 수 있다.
- 상위, 하위 호환성의 문제가 발생할 수 있다.
- 효율성의 문제점이 있다. (자바의 내장 직렬화는 성능이 좋지않고 비대하다.)

### `JSON`과 `XML` 그리고 이진 변형

`JSON`, `XML`, `CSV`는 텍스트 형식이라 어느정도 사람이 읽을 수 있지만, 아래와 같은 미묘한 문제가 있다.

- 숫자의 부호화에 애매함이 있다. 
   - XML과 CSV에서는 숫자와 문자열을 구별할 수 없다.
   - JSON에서는 정수와 부동소수점 수를 구별할 수 없다.
- 큰 수를 다루기 힘들다.
- JSON과 XML은 유니코드 문자열을 잘 지원하나, 이진 문자열을 지원하지 않는다.
   - 따라서 base64 부호화를 사용하여 이런 제한을 피한다.
- XML과 JSON은 스키마를 지원하긴하나 강제하지 않는다.
- CSV는 스키마가 아예 없으며 어플리케이션이 칼럼의 의미를 정의해야 한다.

이러한 문제점이 있어도 이들은 사용하기에 충분하다. 


### 이진 부호화

`JSON`과 `XML`은 부호화시 덜 장황해지지만, 이진 형식과 비교하면 둘 다 훨씬 많은 공간을 차지한다.


따라서 `JSON`이외의 `BSON`, `BJSON`, `UBJSON`, `Smile`등이 개발되었고, `XML`대신 `WBXML` 등이 개발되었다. 이러한 부호화 방식은 틈새시장에서 채택되고 있다.

`JSON/XML`데이터 모델은 객체의 모든 필드 이름을 포함해야 한다.

```js
{
  name: "Alice",
  age: 30,
  isAdmin: false,
  skills: ["JavaScript", "React", "Kotlin"],
  address: {
    city: "Seoul",
    zip: "12345"
  }
}
```

![](https://velog.velcdn.com/images/cksgodl/post/87e3beae-efb8-4643-bd8c-8d40aadb97c8/image.png)

이는 위의 그림처럼 필드의 정보(길이, 타입지시자), 필드 이름(아스키 코드), 문자열 값(아스키 코드)로 부호화 되어 표현된다. 이진 부호화가 진행되며 용량또한 81바이트 -> 66바이트로 줄어들게 된다.

아래는 `utf-8`를 활용해 `JSON`을 바이트코드로 변환하는 예제이다.

```js
const jsonObject = {
  name: "Alice",
  age: 30,
  isAdmin: false,
  skills: ["JavaScript", "React", "Kotlin"],
  address: {
    city: "Seoul",
    zip: "12345"
  }
};

const jsonString = JSON.stringify(jsonObject); // JSON 문자열
const byteCode = Buffer.from(jsonString, 'utf-8'); // UTF-8 바이트코드

console.log("JSON 문자열:", jsonString);
console.log("바이트코드:", byteCode);
```

```js
// plainText
{"name":"Alice","age":30,"isAdmin":false,"skills":["JavaScript","React","Kotlin"],"address":{"city":"Seoul","zip":"12345"}}

// 바이트 코드
[123, 34, 110, 97, 109, 101, 34, 58, 34, 65, 108, 105, 99, 101, 34, 44, 34, 97, 103, 101, 34, 58, 51, 48, 44, 34, 105, 115, 65, 100, 109, 105, 110, 34, 58, 102, 97, 108, 115, 101, 44, 34, 115, 107, 105, 108, 108, 115, 34, 58, 91, 34, 74, 97, 118, 97, 83, 99, 114, 105, 112, 116, 34, 44, 34, 82, 101, 97, 99, 116, 34, 44, 34, 75, 111, 116, 108, 105, 110, 34, 93, 44, 34, 97, 100, 100, 114, 101, 115, 115, 34, 58, 123, 34, 99, 105, 116, 121, 34, 58, 34, 83, 101, 111, 117, 108, 34, 44, 34, 122, 105, 112, 34, 58, 34, 49, 50, 51, 52, 53, 34, 125, 125]
```

### 스리프트와 프로토콜 버퍼

아파치 스리프트(`Apache thrift`)와 프로토콜 버퍼(`Protocol Buffers`)는 같은 원리를 기반으로 한 이진 부호화 라이브러리다. 이들은 모두 데이터를 위한 스키마가 필요하다.

스리프트의 경우 _바이너리프로토콜(`BinaryProtocol`)과 컴팩트프로토콜(`CompactProtocol`)_로 나뉘어 지며 구현 과정은 아래 그림과 같다.
 
![](https://velog.velcdn.com/images/cksgodl/post/2351a4d3-dded-4210-8693-e016cb2c120c/image.png)

모두 정확하게 이해할 필요는 없지만, 타입과 필드태그를 활용하여 스키마를 정의한다. 컴팩트 프로토콜의 경우는 압축률이 더 좋은 버전이라고 생각하면 된다.

![](https://velog.velcdn.com/images/cksgodl/post/695ee4ab-3605-46c5-8095-1d106c22e207/image.png)

프로토콜 버퍼는또한 컴팩트프로토콜과 비슷하게 동작하며, `optional` 표시가 추가되었다.

### 필드태그 및 데이터타입과 스키마 발전

앞에서 스키마는 필연적으로 변한다. 이를 __스키마 발전(`Schema evolution`)__이라고 부른다. 스리프트와 프로토콜 버퍼는 제약적으로 이러한 스키마 발전을 지원한다. (optional필드만 삭제 가능, required필드 추가 불가)

## 아브로(Avro)

아파치 에이브로(`Avro`)는 대중적인 이진 부호화 방식이다. 하둡의 하위 프로젝트로 시작했으며 지금은 카프카, 하둡 등 다양한 곳에서 활용된다.

```js
{
  "type": "record",
  "name": "User",
  "namespace": "com.example.avro",
  "fields": [
    {
      "name": "id",
      "type": "string"
    },
    {
      "name": "name",
      "type": "string"
    },
    {
      "name": "age",
      "type": "int",
      "default": 0
    },
    {
      "name": "email",
      "type": ["null", "string"],
      "default": null
    },
    {
      "name": "isActive",
      "type": "boolean",
      "default": true
    }
  ]
}
```

`Avro`는 태그 번호 없이 부호화를 진행하기에 부호화 길이가 가장 짧다. 또한 이는 필드나 데이터 타입을 식별하기 위한 정보가 없다.

![](https://velog.velcdn.com/images/cksgodl/post/45578ac2-dd4f-4d21-baa2-13994b1ccf8a/image.png)

따라서 이를 활용해 파싱하려면 순서대로 필드를 살펴보고 스키마를 이용해 각 필드의 데이터 타입을 미리 파악해야 한다. __정확히 같은 스키마__를 사용하는 경우에만 이진 데이터를 올바르게 복호화할 수 있음을 의미한다.

### 읽기 스키마와 쓰기 스키마

에이브로를 부호화하길 원한다면 __스키마 버전__을 활용해야 한다. 따라서 쓸 때의 스키마를 __쓰기 스키마(Writer's Schema)__, 읽을 때의 스키마를 읽기 __스키마(Reader's Schema)__ 라고 한다.

> 이러한 복호화 코드는 어플리케이션이 빌드하는 동안 생성된다. `Avro`의 핵심 아이디어는 쓰기 스키마와 읽기 스키마가 동일하지 않아도 되며 호환 가능하면 된다는 것이다. 

`Avro`라이브러리는 쓰기 스키마와 읽기 스키마를 함께 살펴본 다음 쓰기 스키마에서 읽기 스키마로 데이터를 변환해 그 차이를 해소한다.

필드 순서가 달라도 된다. 이는 이름으로 필드를 일치시키기 때문이다. 또한 읽기 스키마에 있고 쓰기 스키마에 존재하는 필드를 만나면 이 필드는 무시한다. 반대의 경우에는 `default`값으로 채운다.

![](https://velog.velcdn.com/images/cksgodl/post/c237de36-521a-4699-a29c-5455737c676d/image.png)

### 스키마 발전 규칙

`Avro`는 디폴트 값과 무시를 통해 상위 호환성과 하위 호환성을 모두 제공한다.

> 디폴트 값으로 `null`은 지원하지 않는다. 이를 지원하려면 __유니온 타입(`union type`)__을 사용해야 한다. 

`Avro`는 타입을 변환할 수 있으므로 데이터타입 변경이 가능하다. 필드 이름 변경도 가능하지만 조금 까다롭다. 읽기 스키마는 필드 이름의 별칭을 포함할 수 있다. 이를 통해 예전 쓰기 스키마 필드 이름을 매치할 수 있다. 즉, 필드 이름 변경은 하위 호환성이 있지만 상위 호환성은 없다.

### 그러면 쓰기 스키마는 무엇인가?

모든 레코드에 스키마를 포함시킬 수는 없는데 쓰기 스키마를 어떻게 알 수 있을까?? 이는 상황에 따라 다르다.


#### 하둡

`Avro`의 일반적인 용도는 모두 동일한 스키마로 부호화된 수백만 개의 레코드를 포함한 큰 파일을 저장하는 용도이다. 따라서 이 파일 쓰기는 파일의 시작 부분에 한번만 쓰기 스키마를 포함시키면 된다. 하둡에서는 이를 위해 __컨테이너 파일(`object container file`)__을 명시한다.

#### 개별 기록된 레코드를 가진 데이터베이스

데이터베이스의 다양한 레코드들은 여러 쓰기 스키마를 활용해 쓰일 수 있다. 따라서 레코드의 시작 부분에 버전 번호를 포함하고 데이터베이스에는 스키마 버전 목록을 유지한다. 읽기는 레코드를 가져와 버전 번호를 추출한 다음 데이터베이스에서 스키마를 가져와 이를 활용한다.

> #### 스키마 레지스트리 활용 (카프카)
>
> 책에서 나오지는 않았지만 카프카에서는 스키마 레지스트리를 활용할 수 있다. 이는 데이터베이스와 비슷하게 스키마 정의를 중앙에서 관리하는 시스템이다. 이를 통해 프로듀서와 컨슈머가 다른 스키마를 사용하여도 버전만 명시한다면 호환이 가능하다.

#### 네트워크 연결을 통해 레코드 내보내기 (RPC, REST)

네트워크 연결을 통해 스키마 버전을 합의하고, 이후 연결동안 동일한 스키마를 활용한다.

스키마 버전을 활용하는 데이터베이스는 어떤 경우에도 유용하다.



### 동적 생성 스키마

`Avro`는 필드의 동적 생성에 친화적이다. 새로운 칼럼을 추가하고 데이터를 내보낸다. 내보내는 과정에 신경 쓸 필요가 없다.(버전만 올리면 됨) 또한 새로운 데이터 파일을 읽는 사람은 레코드 필드가 변경된 사실을 알지만 이름으로 식별되기에 이전 읽기 스키마와 매치 가능하다.

### 코드 생성과 동적 타입 언어

`Avro`는 쓰기 스키마 코드를 직접 만들수도 있고, 객체 컨테이너 파일이 있다면 라이브러리를 활용해 간단히 `JSON`파일을 보는 것과 같이 데이터를 볼 수 있다. 

### 스키마의 장점

앞단에서 살펴보았듯 스리프트, 프로토콜 버퍼, `Avro`는 스키마를 활용해 이진 부호화를 제공하며, 유효성 검사 또한 지원한다.

`JSON`, `XML`을 활용할 수 있지만 이진 부호화 활용 역시 좋은 선택이다.

- 부호화된 데이터 필드 이름을 생략할 수도 있다.
   - 포로토콜 버퍼, 스리프트
- 스키마를 통해 최신 데이터인지 알 수 있다.
- 스키마 데이터베이스를 통해 상위 호환성과 하위 호환성을 제공한다.
- 스키마로부터 코드를 생성하면 컴파일 시접에 타입 체크를 할 수 있다.


## 데이터플로 모드

 데이터플로란 하나의 프로세스(또는 네트워크)에서 다른 프로세스로 데이터를 전달하는 것을 의미한다. 이번장에서는 데이터의 복호화 및 메시지 전달에 대해 알아본다.
 

### 다양한 시점에 기록된 다양한 값 (데이터 베이스)

이진 부호화된 데이터베이스에 여러 사용자가 동시에 접근할 때 상위 호환성 및 하위 호환성을 지켜야 한다.

5년 전의 데이터가 아직도 살아있을 수 있다. (데이터가 코드보다 더 오래 살 수 있다.(`data outlives code`)) 

데이터를 새로운 스키마로 다시 기록하는 작업은 가능하지만, 너무 비싸다. 따라서 대부분의 RDB에서는 기본값을 갖는 새로운 칼럼을 추가하는 변경을 허용한다.

따라서 스키마 발전은 기본 저장소가 여러 가지 버전의 스키마로 부호화된 레코드를 포함해도 전체 데이터베이스가 단일 스키마로 부호화된 것 처럼 보인다.

### 보관 저장소

백업 목적이나 데이터 웨어하우스로 적재하기 위해 데이터베이스의 스냅숏을 수시로 만든다고 가정해보자. 이 경우 덤프는 최신 스키마를 활용해 부호화하기에 `Avro`를 활용하기 좋다. 또한 파케이와 같은 분석 친화적인 칼럼 지향 형식으로 데이터를 부호화할 좋은 기회이기도 하다.

## 서비스를 통한 데이터플로: REST 및 PRC

![](https://velog.velcdn.com/images/cksgodl/post/2a639984-641a-48ac-95c4-ac11bbdba2ba/image.png)

일반적으로 클라이언트와 서버의 역할로 통신을 수행한다. 서버가 공개한 API를 서비스라고 한다.

나아가 서비스 자체가 다른 서비스의 클라이언트가 될 수 있따. 이런 어플리케이션 개발 방식을 __서비스 지향 설계(`service-oritented architecture, SOA`)__ 라고 불렀으며 최근에들어 __마이크로 서비스 설계(`microservices architecture`)__ 라는 이름을 재탄생 했다.

이런 구조의 핵심 설계 목표는 배포와 변경에 독릭접으로 대응한다는 것이다. 각 서비스는 다른 서비스와의 조정 없이 출시될 수 없고, 서버와 클라이언트가 사용하는 데이터 부호화는 __API__의 버전 간 호환이 가능해야 한다.

### 웹 서비스

REST의 기본 프로토콜을 `HTTP`를 사용한다 이를 웹 서비스라고 한다. 사실 웹뿐만 아니라 다른 상황에서도 사용되기에 약간 잘못된 표현이다. (모바일 디바이스의 웹앱에서도 이는 실행된다.)

웹 서비스의 방법론으로 대표적인 `REST` 및 `SOAP`이 있다. `REST`는 프로토콜이 아니라 `HTTP`의 설계원칙을 토대로 한 설계 철학이다. 특징으로는 다음과 같다.

- URL을 사용해 리소스를 식별
- 캐시 제어, 인증, 콘텐츠 유형 협상 등에는 `HTTP`기능을 활용
- 메소드를 통해 목표를 정의

`SAOP`에 비해 인기를 얻고 있으며 `REST`원칙에 따라 설계된 `API`를 `RESTful`이라고 한다.

반대로 `SOAP`은 `XML`기반 프로토콜이다. (`WDSL`이라 불리기도 한다.) 이는 메서드 호출을 통해 원격 서비스에 접근가능한 코드 생성이 가능하다. 

`RESTful API`는 간단한 접근 방식을 선호한다. 스웨거등의 오픈 API도 제공한다. 

![](https://velog.velcdn.com/images/cksgodl/post/bcd307b6-487b-4432-aa4b-b986506d3d9c/image.png)

### 원격 프로시저 호출(`RPC`) 문제

> RPC란?
> 
> **RPC (Remote Procedure Call)**는 네트워크를 통해 분산 시스템의 서로 다른 노드에서 실행되는 프로그램이나 서비스를 호출하는 방식이다. 간단히 말하면, 한 시스템의 프로세스가 다른 시스템에서 실행되는 프로세스를 호출할 수 있도록 하는 기술이다.

RPC의 작동 원리는 다음과 같다.

1. 클라이언트 요청: 클라이언트 프로그램이 원격 프로세스를 호출하기 위해 요청을 생성한다.
2. 직렬화: 요청 데이터(매개변수 등)를 네트워크를 통해 전달할 수 있는 형식으로 변환. 이를 **마샬링(marshalling)**이라고 한다.
3. 서버 처리: 서버는 요청을 수신하고 해당 프로세스를 실행한다.
4. 결과 반환: 실행 결과를 직렬화하여 클라이언트에게 반환한다.

RPC는 호출되는 코드가 로컬에 있는 것처럼 동작하므로, 개발자는 네트워크 관련 세부사항을 신경 쓰지 않고 원격 프로세스를 호출할 수 있다. 이를 __위치 투명성(`location tranparency`)__ 라고 한다. 

하지만 `RPC` 방식은 근본적으로 문제점이 있다. 네트워크 요청은 예측이 불가능하다. 따라서 네트워크 장애나 지연으로 인해 호출이 실패할 수 있고, 요청과 응답의 직렬화 및 네트워크 통신으로 인해 성능 저하가 발생할 수 있다. 또한 네트워크를 통해 전송되어야 함으로 바이트후호화 등의 오버헤드가 발생한다.

이런 문제에도 `RPC`는 사라지지 않는다. 모든 부호화 기능 위에 다양한 `RPC` 프레임워크가 개발되어 사용되고 있다. 


### 메시지 전달 데이터플로의 변화

오늘날은 `MSA`구조가 발전하고 메시지를 전달하는데 바로 전송하지 않고 임시로 메시지를 저장하는 __메시지 브로커(`message broker`)__ 또는 __메시지 큐(`message queue`)__ 또는 __메시지 지향 미들웨어(`message-oriented middleware`)__ 라는 중간 단계를 거쳐 전송한다.

이는 데이터베이스를 활용하는 방법과 유사하지만 다음과 같은 장점이 있다.

- 수신자가 사용 불가능해도 브로커가 버퍼로 사용될 수 있다.
- 죽었던 프로세스에 메시지를 재전송 가능하기에 메시지 유실을 방지할 수 있다. 
- 송신자(`sender`)가 수진자의 IP주소나 포트를 알 필요 없다.
- 하나의 메시지를 여러 수신자로 전송할 수 있다.
- 논리적으로 송신자는 수신자와 분리된다.

### 메시지 브로커

![](https://velog.velcdn.com/images/cksgodl/post/a5a684d2-97dd-4124-98f8-dd3b76d71db6/image.png)

오늘날 레빗MQ, 아파치 카프카 등의 다양한 오픈소스 구현이 대중화됐다. 세부적인 구현은 설정 및 구현에 따라 다르다. 하지만 일반적으로 다음과 같이 사용된다.

> 프로세스 하나가 메시지를 이름이 지정된 큐나 토픽으로 전송하고 브로커는 해당 큐나 토픽을 하나 이상의 소비자 또는 구독자에게 메시지를 전달한다.

토픽은 단방향 데이터플로만 제공한다. 하지만 소비자가 소비 후 메시지를 공급하여 양방향 통신처럼 통신할 수 있다.

### 분산 액터 프레임워크

__액터 모델(`actor model`)__ 에 기반을 둔 소프트웨어 설계 패턴은 특히 분산 환경에서의 동시성 및 병렬성을 효율적으로 관리하기 위해 사용된다.  액터 모델은 분산 시스템에서 개별 단위를 **액터(Actor)**로 추상화하여, 이들이 상태와 동작을 캡슐화하고 메시지 기반의 통신을 통해 상호작용한다.

분산 액터 프레임워크의 주요 특징은 다음과 같다.

- 액터는 독립적인 실행 단위이며, 자체 상태와 동작을 가진다.
   - 액터 간의 상호작용은 비동기 메시지 전달을 통해 이루어지며, 직접 호출 대신 메시지를 수신하여 처리한다.
- 분산 환경 지원
   - 프레임워크는 여러 물리적 노드에 걸쳐 액터를 배치하거나 이동시키고, 액터 간 통신을 투명하게 처리한다.
- 고가용성과 확장성
   - 분산 액터는 장애 허용(fault tolerance) 및 노드 추가를 통해 시스템의 가용성과 확장성을 극대화한다.
예를 들어, 액터가 있는 노드가 실패하면 다른 노드로 액터를 재배치하여 지속적으로 서비스할 수 있다.

- 상태 캡슐화
   - 액터는 자신의 상태를 외부에서 직접 접근할 수 없도록 보호하며, 이를 통해 상태 관리와 동시성을 자연스럽게 처리한다.


대표적인 예로는 아카(`Akka`), 올리선스(`Orleans`), 얼랭(`erlang`) 등이 있다.

## 정리

데이터 구조를 네트워크나 디스크 상의 바이트열로 변환하는 다양한 방법을 살펴봤다. 이런 부호화의 세부 사항은 아키텍처 및 배포전략에도 영향을 미친다.

많은 서비스에 롤링배포나 카나리 배포가 필요하다. 이에 따라 상위 호환성 및 하위 호환성의 개념은 중요하게 작동한다. 

또한 데이터 부호화의 중요성에 대한 여러 시나리오를 보여주는 데이터플로의 예제를 살펴보았다.

- 데이터베이스에 부호화 데이터를 저장하고 읽을 때 복호화 하는 방식
- 클라이언트가 요청을 부호화 하고 서버는 이를 복호화하는 `REST API`, `RPC` 방식
- 송신자가 부호화하고 수신자가 복호화하는 메시지를 서로 전송해서 메시지 큐(노드) 간 통신하는 비동기 메시지 전달 방식

부호화에 약간의 주의를 기울이면 상하위 호환성 및 롤링 배포가 가능하다는 결론에 다다른다. 이에 따라 어플리케이션의 발전은 빨라지고 배포 빈도도 높아진다.














         
