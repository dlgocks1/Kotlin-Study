# 분산 데이터

여러 장비 간 분산된 데이터 베이스는 다음과 같은 이유로 필요하다.

- __확장성__
   - 데이터 볼륨, 읽기 및 쓰기 부하를 여러 장비로 분산할 수 있다.
- __내결함성 / 고가용성__
  - 장비 하나가 죽더라도 다른 장비가 계속 동작할 수 있다.
- __지연 시간__
  - 전 세계에 사용자가 있다면 사용자와 지리적으로 가까운 곳의 데이터센터에서 서버를 둘 수 있다.
  
## 고부하로 확장

고부하 확장 시 두가지 방법이 있다.

- 수평 확장 (더 많은 장비)
- 수직 확장 (더 강력한 장비)
  
수직 확장은 두 배의 램과 CPU를 활용해도 두 배 이상의 성능을 내진 못한다. 또한 비용도 두 배 이상으로 비싸다. 

따라서 고부하를 활용 시 공유 디스크 아키텍쳐를 활용한다. 공유 디스크 아키텍처는 독립적인 CPU 및 RAM을 탑재한 여러 장비를 사용하지만 
각 고속 네트워크로 연결되며 데이터 저장은 장비 간 공유하는 디스크 배열에 한다. 

### 비공유 아키텍쳐

비공유 아키택쳐(`shared-nothing`)(수평 확장이나 규모확장이라고도 함)는 대중적으로 활용된다. 데이터베이스 소프트웨어를 수행하는 각 장비나 가상 장비를 **노드**라고 부르며 CPU, RAM, 디스크 등을 독립적으로 사용한다.

이러한 구조는 최상위 하드웨어를 사용할 필요가 없다. 하지만 분산 시스템에서 발생하는 제약 조건과 트레이드오프를 이해해야 한다. 이에 대한 내용은 추후에 알아본다.

### 복제와 파티셔닝

- 복제 (`replica`)
   - 같은 데이터의 복제를 잠재적으로 다른 위치에 있는 노드에 유지한다. 
   - 일부 노드가 사용불가능 상태라면 해당 데이터는 남은 다른 노드를 통해 여전히 제공할 수 있다.
- 파티셔닝 (`sharding` or `partition`)
  - 큰 데이터베이스를 파티션이라는 작은 서브셋으로 나누고, 각 파티션에 다른 노드를 할당한다.
  - 데이터가 분산저장되지만 한 파티션 전체가 장애나면 데이터가 손실될 수 있다.
  
![](https://velog.velcdn.com/images/cksgodl/post/474483de-72da-4091-bdaa-eb3970c0c66a/image.png)

# 05. 복제

데이터의 복제(`replica`)를 위해서는 데이터가 변경 될 때마다 복제 처리를 해주어야 하고 이에 따라 세 가지 인기있는 알고리즘을 알아본다.

- 단일 리더(`single-leader`)
- 다중 리더(`multi-leader`)
- 리더 없는(`leaderless`)

## 리더와 팔로워

데이터베이스의 복사본을 저장하는 서버를 복제 서버(`replica`)라고 한다. 다중 복제 서버를 활용하면 모든 데이터가 동일하다는 것을 어떻게 보장할까?

데이터베이스의 모든 쓰기는 복제 서버에서 처리돼야 한다. 이에 따라 가장 일반적인 해결책인 리더 기반 복제(마스터 슬레이브 복제)라고도 한다.

동작과정은 다음과 같다. 복제 서버 중 하나를 **리더(`leader`)**로 지정하고 쓰기 요청은 모두 리더에게 보낸다. 리더는 먼저 로컬 저장소를 업데이트 후에 다른 복제본을 업데이트 한다. 

> 여기서 다른 복제 서버를 **팔로워(read replica, 슬레이브)**등이라고 한다. 

리더가 로컬 저장소에 새로운 데이터를 기록할 때 마다 데이터변경을 **복제 로그(replication log)**나 **변경 스트림(change stream)**의 일부로 팔로워에게 전송한다. 팔로워는 리더가 처리한 것과 동일하게 로컬 복사본을 갱신한다.

질의의 경우는 리더 또는 슬레이브에게 질의한다. (설정에 따라 다르다. `read preference`설정을 통해 슬레이브에게만 질의할 수도 있다.

![](https://velog.velcdn.com/images/cksgodl/post/4914b8b0-423d-459f-a55e-9cfaefafe3cb/image.png)

> 이러한 리더 기반 복제는 데이터베이스에만 국한되지 않는다. 카프카같은 고가용성 큐같은 분산 메시지 브로커에도 사용된다.

#### read preference예제

- Ref : [MongoDB read preference](https://www.mongodb.com/ko-kr/docs/manual/core/read-preference/)

- mongo read perference

![](https://velog.velcdn.com/images/cksgodl/post/2b7b0f54-abb0-42cf-9d8a-bdd003c9dd5a/image.png)

- [읽기 및 쓰기 일관성](https://www.mongodb.com/ko-kr/docs/manual/core/causal-consistency-read-write-concerns/)

`readConcern`이 `majority`인 경우 해당 데이터를 복제본의 과반수가 승인했음을 보장한다.

`writeConcern`이 `majority`인 경우 과반수가 로컬 `oplog`에 변경 사항을 기록했음을 의미한다.

![](https://velog.velcdn.com/images/cksgodl/post/3768ed3b-b2a1-4540-858e-dd05c4b4063c/image.png)

> 참고)
>
> - 쓰기 후 읽기 : 쓰기후에 읽었을 때 쓴 값이 읽어 지는지
- 단조적 읽기 : 최신 복제 서버에서 먼저 읽고 다음, 예전 복제서버에서 읽는 것
- 단조적 쓰기 : 최신 복제 서버에 쓰고 이전 복제서버에 쓰는 것
- 읽기 후 쓰기 : 읽고 값을 썼을 때 읽은 값이 써지는지


### 동기 및 비동기 복제

복제 시스템의 중요한 세부 사항은 **동기식**으로 발생하는지, **비동기식**으로 발생하는지 여부다. 

![](https://velog.velcdn.com/images/cksgodl/post/677d0d4f-0c87-432a-a16e-8c263fefaab8/image.png)

위의 예제에서 팔로워1은 동기식이고 팔로워2는 비동기식이다. (팔로워2가 느리게 표현되어 있지만 예시이고 실제로 저렇게 느리지 않다.)

동기식의 장점은 리더와 일관성 있는 데이터를 언제나 유지할 수 있는 점이지만, 팔로워가 죽거나 응답하지 않으면 쓰기 처리될 수 없고 모든 쓰기가 차단되어야 한다. 

> 따라서 모든 팔로워가 동기식인 경우는 비현실적이다. 따라서 현실적으로 팔로워 하나를 동기, 나머지 하나를 비동기식으로 하는 **반동기식**구조가 있다.

보통 리더 기반 복제는 완전한 비동기식으로 구현된다. 이 경우 리더가 잘못된 경우 팔로워에 아직 복제되지 않은 모든 쓰기는 유실된다. 이것은 쓰기가 클라이언트에게 확인된 경우에도 지속성을 보장하지 않는다는 의미이다. 

### 새로운 팔로워 설정

복제 서버 수를 늘리거나 장애 노드의 대체를 위해 새로운 팔로워를 설정해야 한다. 새로운 팔로워가 리더의 데이터 복제본을 정확히 가지고 있는지 어떻게 보장할까?

1. 데이터베이스를 잠그지 않고 리더의 스냅샷을 가져온다.
2. 스냅샷을 새로운 노드에 복사한다.
3. 팔로워는 리더에 연결해 스냅샷 이후의 모든 쓰기 로그를 가져온다. (`log sequence number` or `binlog coordinate`)
4. 팔로워가 스냅숏 이후 데이터 변경의 미처리분(`backlog`)를 모두 처리했을 때 따라잡았다고 알리며, 리더의 데이터 변화 스트림을 구독하여 처리한다.

### 노드가 중단됐을 때 처리

개별 노드가 장애나도 전체 시스템은 작동해야 한다. 리더 기반 복제에서의 고가용성 달성 방식을 알아보자.

#### 팔로워 장애 : 따라잡기 복구

각 팔로워는 데이터 변경 로그를 로컬 디스크에 보관한다. 따라서 팔로워가 죽어도 보관된 로그에서 마지막 트랜잭션 로그를 알아내고, 이후의 데이터 변경 로그를 다시 받아와 재처리할 수 있다.

#### 리더 장애: 장애 복구

리더 장애를 처리하는 일은 까다롭다. 팔로워 중 하나를 새로운 리더로 승격해야 하고, 새로운 리더로 쓰기를 전송하기 위해 재설정이 필요하며, 다른 팔로워는 새로운 리더로부터 데이터 변경을 소비하기 시작해야 한다. (이러한 과정을 **장애 복구(failover)**라고 한다.

장애 복구의 과정은 다음과 같다.

1. 리더가 장애인지 판단한다.
   - 보통 하트비트(타임아웃)을 기준으로 사용한다.
2. 새로운 리더를 선출한다.
   - 슬레이브끼리의 투표로 선출한다. 자세한 과정은 9장에서 다룬다.
3. 새로운 리더 사용을 위해 시스템을 재설정한다.
   - 클라이언트는 새로운 쓰기 요청을 리더에게 보내야한다. 따라서 새로운 리더임을 슬레이브들에게 알려야 한다.

> - [분산 시스템의 내결함성을 높이는 뗏목 합의 알고리즘(Raft Consensus Algorithm)과 정족수(Quorum) 개념 알아보기
](https://seongjin.me/raft-consensus-algorithm/)
  - ![](https://velog.velcdn.com/images/cksgodl/post/6550b7a2-224a-4c44-9caf-f81eac39fd72/image.png)
- _몽고의 Arbiter_
  - ![](https://velog.velcdn.com/images/cksgodl/post/2cb528d5-d52f-4956-b588-b26ac6d3abfc/image.png)



하지만 이러한 과정은 잘못될 수 있는 것 투성이다.

- 비동기식 복제를 사용한다면 새로운 리더가 실패하기 이전 요청을 일부 수신하지 못할 수 있다. 
- 유효하지 않은 팔로워가 승격되어 뒤쳐진 인덱스 키로 값을 저장하여 잘못된 유저 정보가 공개된 적 있다.
- 죽었던 노드가 다시 살아나 두 노드가 모두 자신이 리더라고 믿을 수 있다. __스플릿 브레인__이라고 하기도 하며 데이터가 유실되거나 오염될 수 있다.

### 복제 로그 구현 방식

리더 기반 복제는 어떻게 동작할까? 다양한 동작방법의 예를 알아보자.

#### 구문 기반 복제

> 구문은 단위 요청(구문(`statement`))이라고 생각하면 된다.
>
> 몽고에서는 주로 `oplog`라 불리우는 구문로그를 기반으로 복제를 수행한다.

간단한 사례를 알아보자. 

1. 리더는 모든 쓰기 요청(구문)을 기록하고 쓰기를 실행하고, 구문을 팔로워에게 전송한다. 
2. 각 팔로워는 리더의 구문을 받아 실행한다.

해당 방식은 합리적인 것 같지만 복제가 깨질 수 있는 사례가 있다.

- `NOW()`나 `RAND()`와 같은 구문은 다른 값을 생성할 수 있다.
- 자동증가 칼럼이나 컨디션 구문은 같은 순서로 실행되어야 한다. 따라서 동시에 여러 트랜잭션이 수행되는 것이 제한된다.

#### 쓰기 전 로그 배송

![](https://velog.velcdn.com/images/cksgodl/post/d3ed19ac-d2ff-4708-833d-1f70c5c35ac6/image.png)

- `SS테이블`, `LSM 테이블`의 경우 로그 자체가 저장소의 주요 부분이다. 로그 세그먼트는 작게 컴팩션되고, 백그라운드로 가비지 컬렉션을 수행한다.
- `B트리`의 경우 모든 변경을 쓰기 전 로그(`WAL`)에 쓰기 때문에 고장 이후 일관성 있는 상태를 복원할 수 있다.
   - `WAL`은 디스크 블록에서 어떤 바이트를 변경했는지와 같은 저수준의 데이터를 포함한다. 따라서 복제가 저장소 엔진과 밀접하게 엮인다. **소프트웨어나 저장소 형식을 다른 버전을 활용한다면 실행할 수 없다.**

#### 논리적(로우 기반) 로그 복제

복제 로그를 저장소 엔진 내부와 분리하기 위한 대안 하나는 복제와 저장소 엔진을 위해 다른 로그 형식을 사용하는 것이다. __이 같은 종류의 복제 로그를 저장소 엔진의 (물리적) 데이터 표현과 구별하기 위해 논리적 로그(logical log)라고부른다.__

> 데이터를 변경한 SQL 쿼리가 아니라, 각 데이터 행(로우)에 대해 실제로 발생한 변경 사항을 기록한다.

이에따라 팔로워에서 다른 버전의 데이터베이스 소프트웨어나 다른 저장소 엔진을 활용할 수 있다.

또한 논리적 로그 형식은 외부 어플리케이션이 파싱하기 쉬우며, 오프라인 분석이나 사용자 정의 색인, 캐시 구축을 위해 외부 시스템의 데이터베이스 내용을 전송하고자 할 때 사용된다. 이 기술을 __변경 데이터 캡쳐(`change data capture`)__ 라 부른다.

![](https://velog.velcdn.com/images/cksgodl/post/1901b775-1025-4d7f-bd64-b60a037bdc12/image.png)

#### [Mongo CDC](https://www.mongodb.com/ko-kr/docs/kafka-connector/current/sink-connector/fundamentals/change-data-capture/)
![](https://velog.velcdn.com/images/cksgodl/post/7cb6db4b-b333-48ad-880d-a4e2aa709334/image.png)

몽고에서는 카프카커넥터를 활용한 CDC를 제공하며 이는 `oplog`를 기반으로 작동한다.

`oplog`는 모든 쓰기 작업(insert, update, delete)을 기록하며, 이를 관찰하여 `tailing cursor`를 통해 해당 로그 콜렉션을 읽어서 타 컴포넌트로 전송한다.

옵션에 따라 변경된 도큐먼트의 전체 내용을 가져오는 것도 가능하다.


#### 트리거 기반 복제 (어플리케이션 단)

이러한 복제 방식을 어플리케이션 코드에서 활용하고 싶을 수 있다. 따라서 많은 관계형 데이터베이스에서 사용할 수 있는 기능인 __트리거__나 __스토어드 프로시저__를 활용한다.

> __트리거__는 사용자 어플리케이션 코드를 등록할 수 있게한다. 따라서 해당 코드는 데이터베이스가 변경되면(쓰기 트랜잭션) 자동으로 실행된다. 

해당 방식은 복제에 많은 오버헤드가 있고, 많은 버그나 제한 사항이 발생하지만 유연성 때문에 유연하다.

## 복제 지연 문제

복제는 확장성 및 지연 시간의 필요에 따라 생기게 되었다. 

> 데이터베이스의 복제 구조는 리더만 쓰고, 이외의 복제본에서 읽기를 수행한다. 이런 방식을 읽기 확장(`read-scaling`)이라 한다.

복제본이 존재하면 팔로워를 더 추가함으로 더 많은 읽기 처리요청을 감당할 수 있다. 팔로워가 뒤쳐진다면 지난 정보를 볼 수 있다. 하지만, 최종적에는 팔로워가 모든 쓰기를 따라잡게되기에 이런 효과를 __최종적 일관성__ 이라 한다.

__복제 지연__ 이란 리더와 팔로워 사이의 반영 지연 시간을 의미한다. (대체로 매우 짧은 순간) 하지만 이러한 불일치는 큰 문제가 될 수 있다.

![](https://velog.velcdn.com/images/cksgodl/post/0ed1a4d6-d006-4883-8caa-b95c6304c2ff/image.png)

이러한 복제 지연으로 인한 여러 `read-concern`, `write-concern`문제가 생길 수 있다. 아래는 그 내요을 알아본다.

### 쓰기 후 읽기

많은 어플리케이션은 사용자가 임의 데이터를 제출하고 제출한 데이터를 볼 수 있어야 한다. 복제 지연이 길다면 해당 상황에서 문제가 생길 수 있다.

![](https://velog.velcdn.com/images/cksgodl/post/86b6bcc4-c9ef-4f43-9333-cb27a8fec61a/image.png)

이에 따라 __쓰기 후 일관성(자신의 쓰기 읽기 일관성)__ 이 필요하다.

이를 구현하는 아래와 같은 방법이 있다.

- 사용자가 수정한 내용을 읽을 때는 리더에서 읽는다. 그 밖에는 팔로워에서 읽는다. (X)
   - 본인 소유 프로필은 리더에서 읽고, 다른 사용자 프로필은 팔로워에서 읽는 규칙을 활용한다.
- 마지막 갱신 후 1분 동안은 리더에서 모든 읽기를 수행한다. (X)
- 요청 시 클라이언트의 마지막 갱신 `timestamp`를 활용하여 복제본이 해당 `timestamp`까지 요청을 따라잡았는지 확인하고 질의를 수행한다. (X)

또한 서로 다른 디바이스에서 접근할 때 같은 내용을 출력해야 한다. 이에따라 몇 가지 더 고려해야 한다.

- 사용자의 마지막 갱신 타임스탬프를 활용하는 것은 불가능하다. 따라서 해당 메타데이터를 중앙집중식으로 관리한다. (O)
- 복제 서버가 여러 데이터센터 간에 분산되어 있다면 다른 디바이스의 연결이 동일한 데이터센터로 라우팅된다는 보장이 없다. 따라서 리더에서 읽어야 할 필요가 있으면 해당 요청을 같은 데이터센터로 라우팅해야 한다. (X)

### 단조 읽기

비동기식 팔로워에서 발생할 수 있는 두 번째 이상현상은 __시간을 거꾸로 흐르는 응답__ 이다.

![](https://velog.velcdn.com/images/cksgodl/post/ca69ffab-c6f0-4bde-b08c-692e11d5e48d/image.png)

> __단조 읽기(monotonic read)__ 는 사용자의 최신 복제 서버에서 먼저 읽고 다음, 예전 복제서버에서 읽는다. 

단조 읽기를 달성하는 한 방법은 각 사용자의 읽기가 항상 동일한 복제 서버에서 수행되게끔 하는 것이다. 

### 일관된 순서로 읽기

![](https://velog.velcdn.com/images/cksgodl/post/68c468a5-c12c-4eda-85fe-f147d6479805/image.png)

위와 같은 현상을 방지하려면 __일관된 순서로 읽기(Consistent Prefix Read)__ 가 필요하다. 

많은 분산데이터베이스에서 서로 다른 파티션은 독립적으로 동작함으로 전역 순서는 없다. 따라서 예전 상태의 일부와 새로운 상태를 함께 볼 수 있다. 

동일한 파티션에 작성하는 방법은 효율적이지 않기에 인과성을 명시적으로 유지하는 알고리즘을 이후 [이전 발생 관계와 동시성]()에서 다시 설명한다.


## 다중 리더 복제

단일 리더 기반 복제에는 큰 문제점이 있다. 리더가 장애나면 데이터베이스에 쓰기가 불가능하다는 점이다. __따라서 리더 기반 복제 모델은 쓰기를 허용하나 노드를 하나 이상 두는 것으로 확장된다.__ 쓰기 처리를 하는 각 노드는 데이터 변경을 다른 모든 노드에 전달한다. 이 방식을 __다중 리더__ 방식이라 한다.(마스터 마스터 or 액티브/액티브 목제)

### 다중 리더 복제의 사례

#### 다중 데이터센터 운영

지리적으로 가까이 위치하기 위해 다중 데이터센터를 활용하는 경우 각 데이터센터 마다 리더가 있을 수 있다. 

![](https://velog.velcdn.com/images/cksgodl/post/034d7bcb-bde0-4e7f-9216-9c9815e20c43/image.png)

각 리더간의 동일한 데이터간의 쓰기 충돌은 반드시 발생하며 이를 해결해야 한다. 또한 다중 리더 복제는 자동 증가 인덱스 키, 트리거, 무결성 제약은 문제가 될 소지가 많다. 

#### 협업 편집

동시에 여러사람이 문서를 편집할 수 있는 어플리케이션 (구글 독스)등 의 예제가 있다. 이는 데이터베이스 복제 사례와는 다르지만, 공통점이 있다. 한 사용자가 문서를 편집할 때 변경 내용을 즉시 로컬 복제 서버에 적용하고 나서 동일한 문서를 편집하는 다른 사용자와 서버에 비동기 방식으로 복제한다.

_편집 충돌이 없음을 보장하려면 문서의 잠금을 얻어야 한다. 이런 방식은 트랜잭션을 사용하는 단일 리더 복제와 동일하다._

#### 쓰기 충돌 다루기

다중 리더 복제의 가장 큰 문제는 쓰기 충돌이 발생한다는 점이다. 이에 따라 충돌 해소가 무조건 필요하다.

![](https://velog.velcdn.com/images/cksgodl/post/3403659d-b4a2-45be-ba92-3ce393ae30e4/image.png)

### 동기 대 비동기 충돌 감지

단일 리더 데이터베이스에서는 동기적으로 작성해 충돌을 피한다.

다중 리더 데이터베이스에서도 충돌 감지를 동기식으로 만들 수 있지만, 이러면 다중 리더 복제의 주요 장점을 잃어버린다. 

### 충돌 회피

충돌을 처리하는 간단한 전략을 충돌이 일어나지 않게 회피하는 것이다. 특정 레코드의 모든 쓰기가 동일한 리더를 거치도록 어플리케이션이 보장한다면 충돌은 발생하지 않는다.

사용자가 자신의 데이터를 편집할 수 있는 어플리케이션에서 특정 사용자의 요청을 동일한 데이터센터로 항상 라우팅하고 데이터센터 내 리더를 사용해 읽기와 쓰기를 하게끔 보장할 수 있다. 이에 따라 다른 사용자는 서로 다른 데이터센터를 가질 수 있지만, 사용자의 관점에서는 단일 리더이다.

하지만, 한 데이터센터가 고장나면 다시 라우팅하고, 다른 리더에서 동시 기록 가능성을 대처해야 한다.

### 일관된 상태 수렴

데이터 저장 시 각 리더간의 일관성은 유지되어야 한다. 리더 1의 최종 값이 C이고, 리더 2의 최종 값이 B가되면 안된다. 

따라서 데이터베이스는 수렴(`convergent`)방식으로 충돌을 해소해야 한다. 이는 모든 변경이 복제돼 모든 복제 서버에 동일한 최종 값이 전달되게 해야 한다는 의미이다.

![](https://velog.velcdn.com/images/cksgodl/post/7ddd8abf-451f-443b-817a-1788aea7bb25/image.png)

이를 구현하기 위한 방식은 다양하다.

- 각 쓰기에 고유 ID(타임스탬프, 해시 값, UUID 등)을 부여하고 가장 높은 ID요청만 쓰기를 허락한다. 타임스탬프를 사용하는 경우를 최종 쓰기 승리(`last write wins, LWW`)라고 한다. 
- 각 복제 서버에 ID를 부여하고 높은 숫자의 복제 서버에서 생긴 쓰기가 항상 우선적으로 적용되게 한다.
- 값을 어떻게든 병합한다. (B/C)
- 명시적으로 충돌을 기록한다.

### 사용자 정의 충돌 해소 로직

대부분 다중 리더의 충돌해소는 어플리케이션 코드단에서 수행된다. 쓰기 및 읽기 도중 충돌에 맞추어 코드를 실행한다.

하지만, 충돌을 해소하기 위한 구조도 있다.

- __충돌 없는 데이터 타입 사용__ : 셋, 맵, 카운터 등의 데이터 구조의 집합으로 충돌을 해소한다.
- __병합 가능한 영속 데이터 구조__ : 깃 버전과 유사하게 히스토리를 추적하고 삼중 병합 함수를 사용한다.
   - 병합정렬 
    ![](https://velog.velcdn.com/images/cksgodl/post/093749b3-f1c8-4fec-a162-4d6008059be9/image.png)

- __운영 변환(operational transformation)__ : 구글 독스와 같은 협업 편집 어플리케이션 충돌 해소 알고리즘이다.


### 다중 리더 복제 토폴로지

> __복제 토폴로지__ 는 쓰기를 한 노드에서 다른 노드로 전달하는 통신 경로를 의미한다.

#### 원형 토폴로지

`MySQL`의 토폴리지이다.
- 하나의 노드가 장애나면 전체 장애 (단일 장애점)
- 다른 복제 서버에 도달하기 전에 여러 노드를 거쳐야 함
![](https://velog.velcdn.com/images/cksgodl/post/4f7a1c9c-e25a-4d32-8191-f2221eec6891/image.png)

#### 별 모양 토폴로지

- 동일하게 복제를 위해 여러 노드를 거쳐야 함
- 단일 장애점을 가지고 있음

![](https://velog.velcdn.com/images/cksgodl/post/bd83b266-8a0c-4f3a-ab6c-53f055c94f65/image.png)

#### 전체 연결 토폴로지

- 단일 장애점이 없음
- 모든 토폴로지에 복제를 진행

![](https://velog.velcdn.com/images/cksgodl/post/98e4e43c-3b00-43c9-80ce-32210c2e899f/image.png)

- 복제 메시지가 추월되거나 역전될 수 있음
![](https://velog.velcdn.com/images/cksgodl/post/9c8781c2-68a3-4799-81da-d86eac28bcd2/image.png)

따라서 **버전 벡터(`version vector`)**라고 하는 기법을 사용할 수 있다. 

### 리더 없는 복제

일부 저장소 시스템은 리더의 개념을 버리고 모든 복제 서버가 쓰기를 허용한다. 이를 __다이나모 스타일__이라 한다.

### 노드가 다운됐을 때 데이터베이스에 쓰기

리더 없는 설정에서는 장애 복구가 필요하지 않다. 

![](https://velog.velcdn.com/images/cksgodl/post/d31fe48b-95dc-46f4-87c6-2a2883babf2b/image.png)

쓰기와 읽기 모두 복제 노드에 모두 요청함으로써 다운된 노드가 쓰기를 놓친 사실은 무시한다. 만약 오래된 값을 얻는다고 하여도 버저닝을 위해 최신 값을 결정한다.

### 읽기 복구와 안티 엔트로피

사용 불가능한 노드가 온라인이 됬을 때 어떻게 따라잡아야 할까?

다이나모 스타일(리더 없는) 데이터스토어는 다음과 같이 처리한다.

- 읽기 복구
  - 값을 읽은 후 오래된 값이면 쓰기 처리를 진행 
- 안티 엔트로피 처리
  - 백그라운드 프로세스를 두어 데이터 차이를 찾아 복제한다. (복제 로그와 달리 순서로 쓰기를 복사하기에 상당한 시간이 걸릴 수 있음)
  
### 읽기와 쓰기를 위한 정족수

위 그림에서 쓰기를 복제 서버 세 개 중 두 개에서만 처리해도 성공한 것을 간주했다. 이 정족수를 어떻게 정할까?

> 정족수
> 
> 명사 합의체가 의사(議事)를 진행하고 결정하는 데에 필요한 최소한의 출석 인원.

`n`개의 복제 서버가 있을 때 모든 쓰기는 `w`개의 노드에서 성공해야 쓰기가 확정되고 모든 읽기는 최소한 `r`개의 노드에 질의해야 한다. (위의 예는 n=3, w=2, r=2)

이 때 **`w + r > n`**이면 읽을 때 최신 값을 얻을 것으로 기대한다. 이런 r과 w를 따르는 읽기와 쓰기를 정족수 읽기와 쓰기라고 부른다. 

![](https://velog.velcdn.com/images/cksgodl/post/0e58a863-66f9-44b1-8c83-ede1f1b6eabc/image.png)

위의 그림에서는 w=3 + r=3 > n=5 으로 사요 불가능한 노드를 2개까지 용인한다. 

필요한 w나 r개 노드보다 사용 가능한 노드가 적다면 쓰기나 읽기는 에러를 반환한다. 

### 정족수 일관성의 한계

n개의 복제 서버가 있고 위의 공식에 맞추어 `w + r > n`으로 설정한다면 일반적으로 모든 읽기는 최신 값을 반환할 것을 기대한다. 그러나 몇몇의 경우는 정족수를 만족해도 그러지 않는 에지 케이스가 있다.

- 느슨한 정족수를 활용할 경우 w개의 쓰기와 r개의 읽기는 다른 노드에서 수행될 수 있음

![](https://velog.velcdn.com/images/cksgodl/post/efda9aa7-2d0a-477b-969b-6ad4c337b830/image.png)

- 두 쓰기가 동시에 발생하면 타임 스탬프로 결정해야 한다.
- 쓰기가 일부 복제 서버에서는 성공했지만, 다른 복제서버에서 실패했을 경우 이를 롤백하지 않는다. -> 빈 값이 반환될 수 있다.
- 새 값을 전달할 때 고장나면 값을 잃어버린다.

등 수많은 에지 케이스가 있다. 

### 최신성 모니터링

운영 관점에서 볼 때 데이터베이스가 최신 결과를 반환하는지 여부를 모니터링하는 일은 중요하다. 

- 리더 기반 복제에서는 복제 지연에 대한 지표를 노출하며 모니터링 시스템에 제공된다.
   - 모든 쓰기가 리더를 통하기에 가능한 구조이다. 
   - 리더의 현재 위치에서 팔로워의 현재 위치를 빼면 복제 지연량 체크도 가능하다.

- 리더 없는 복제에서는
   - 쓰기가 적용된 순서를 고정할 수 없기 때문에 모니터링이 더 어렵다. 
   - 읽기 복구를 (안티 엔트로피)하는 경우 읽기가 드문 값은 얼마나 오래된 값인지 제한이 없어 아주 오래된 값일 수 있다. 


### 느슨한 정족수와 암시된 핸드오프

장애가 발생해 정족수의 요건에 만족하지는 않지만 클러스터가 연결되어 있는 경우가 있다. 이 경우 쓰기 요청을 받았을 때

- 모든 요청에 오류를 반환한다.
- 일단 연결된 노드에 쓴다.

라는 선택지가 있는데 후자를 __느슨한 정족수__ 라고 부른다. 네트워크 장애 상황이 해제되면 한 노드가 다른 노드를 위해 일시적으로 수용한 모든 쓰기를 "홈"노드로 전송한다. 이 방식을 __암시된 핸드오프__ 라고 부른다.

![](https://velog.velcdn.com/images/cksgodl/post/c059f8d8-e14d-4473-b9e8-5191df32382c/image.png)

느슨한 정족수는 읽기에 대한 정확성을 제공하지 않지만 쓰기 가용성을 높이는 데 특히 유용하다. 

### 동시 쓰기 감지

다이나모 스타일 데이터베이스는 여러 클라이언트가 동시에 같은 키에 쓰는 것을 허용하기 때문에 충돌이 발생한다. 또한 장애 떄문에 이벤트가 다른 노드에 다른 순서로 도착할 수도 있다.

![](https://velog.velcdn.com/images/cksgodl/post/1a3faba1-3dcf-47d9-9299-11d2860e2a61/image.png)

- 클라이언트 B 는 A -> B -> A 의 결과를 받는다.

각 노드가 데이터를 단순히 덮어 쓴다면 일관성이 꺠진다. 최종적인 일관성을 달성하기 위해서는 복제본들이 동일한 값이 돼야 한다. 이를 위해 어플리케이션 개발자는 데이터베이스 내부 충돌을 어떻게 다루는지 알아야 한다.

### 최종 쓰기 승리 (동시 쓰기 버리기)

타임스탬프, 버전벡터 등을 활용해 가장 최신에 쓴 쓰기를 활용할 수 있다. 이는 __최종 쓰기 승리(LWW)__ 라는 충돌 해소 알고리즘이라 불린다.

이는 최종적 수렴 달성을 하지만, 지속성을 희생한다. 동일한 키에 여러번 동시 쓰기가 발생하여도 쓰기 중 하나만 남고 다른 쓰기는 무시된다. 따라서 손실 데이터를 허용하지 않는다면 LWW가 충돌해소로 적합하지 않다.

LWW로 데이터베이스를 안전하게 사용하는 방법은 키를 한번만 쓰고 이후에는 불변 값으로 다루는 것이다. 이를 통해 동시에 갱신하는 상황을 방지한다. 카산드라의 경우는 UUID를 키로 활용해 모든 쓰기 작업에 고유한 키를 부여한다.

### "이전 발생" 관계와 동시성

나중 작업이 발생하면 이전 작업을 덮어 쓸 수 있지만 작업이 동시에 발생하면 충돌을 해소해야 한다.

### 이전 발생 관계 파악하기

동시에 발생한 이벤트를 판별하는 알고리즘을 알아보자. 

![](https://velog.velcdn.com/images/cksgodl/post/17fd5875-fc09-474a-af9a-1fb5a635dba2/image.png)
![](https://velog.velcdn.com/images/cksgodl/post/abadddd5-8ffc-4b9d-aad1-4f1deedcda75/image.png)

위의 예는 동시작업과 이전작업의 예를 나타낸다. 클라이언트는 서버 데이터와 동일한 최신 상태를 유지하지 못하지만, 손실된 쓰기는 없다.

위와같은 버저닝을 통해 동시쓰기를 제어할 수 있다.

### 동시에 쓴 값 병합

위와같이 여러 작업이 동시에 발생하면 이 값을 합쳐 청리해야 한다. 이런 값을 __형제(sibling)__ 값이라 한다.

버전번호 및 타임스탬프 기반으로 선택하는 방식은 데이터 손실이 있다. 따라서 합리적인 접근 방식은 합집합을 취하는 것이다. 

이러한 합집합은 데이터 제거가 될 때는 올바른 결과를 기대할 수 없다. 따라서 이 문제를 방지하려면 상품을 제거할 때 데이터베이스에서 단순히 삭제하면 안되고, 상품을 제거했음을 나타내기 위해 해당 버전 번호에 표시를 한다. 이를 __툼스톤__이라 한다.

### 버전 벡터

단일 복제본이 아니라 다중 복제본일 때 동시 쓰기 제어는 버전 번호로 충분하지 않다. 이 때는 복제본당 버전 번호도 사용한다. 

모든 복제본의 버전 번호 모음을 __버전 벡터(version vector)__ 라 부르며, 해당 값을 활용하여 덮어쓰기와 동시쓰기를 구분한다.

## 정리

이번장에서는 복제(Replica)에 대해 알아보았다. 이는

- 고가용성
  - 한 장비가 끊겨도 계속 동작
- 연결이 끊긴 작업
  - 네트워크 중단이 있어도 동작
- 지연 시간
  - 지리적으로 가까운곳에 데이터를 배치해 더 빠르게 작업
- 확장성
  - 많은 양의 복제본에서 더 많은 읽기 가능

의 용도로 활용될 수 있다. 이런 복제를 구현하기 위해

- 단일 리더 복제
- 다중 리더 복제
- 리더 없는 복제

의 방식이 있다. 이러한 복제는 비동기로 이루어지며 이에따른 몇가지 지연현상이 있다. 이를 해결하기위해 몇가지 모델이 있다.

- 쓰기 후 읽기 일관성
  - 사용자는 자신이 쓰기 후 데이터를 읽어야 한다
- 단조 읽기
  - 예전 시점의 데이터는 보지 않아야 한다.
- 일관된 순서로 읽기
  - 인과성이 있는 상태의 데이터를 봐야한다.
  
또한 다중 리더 복제에서는 동시에 쓰는 상황을 허용하기 떄문에 충돌이 발생할 수 있다. 충돌을 갱신하는 방법에 대해서도 알아보았다.

- 타임스탬프 LWW
- 버전 벡터



## Ref

- https://catsbi.oopy.io/c71c955c-6aa5-452d-93e6-b8fcadcdcba0

