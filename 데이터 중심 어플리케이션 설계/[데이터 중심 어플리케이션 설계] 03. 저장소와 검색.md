대개 어플리케이션 개발자는 데이터베이스를 구현하기보단 적절한 데이터베이스를 선택한다. 따라서 어플리케이션의 작업부하에 따른 적절한 저장소 엔진을 선택해야하고, 이에따른 엔진 작업에 따른 대략적인 개념을 이해해야 한다.

## 데이터베이스를 강력하게 만드는 데이터 구조

`bash`를 통한 세상에서 가장 간단한 데이터베이스를 구현해보자.

```shell
#!/bin/bash

DB_FILE="database.txt"

# Create or add a record to the database
add_record() {
    local key=$1
    local value=$2
    echo "$key,$value" >> "$DB_FILE"
    echo "Record added: $key,$value"
}

# Read a record from the database by key
read_record() {
    local key=$1
    grep "^$key," "$DB_FILE" | while IFS=',' read -r k v; do
        echo "Found: Key=$k, Value=$v"
    done
}
```

위의 쉘과 같은 경우 `add_record`의 경우 꽤 좋은 성능을 보여준다. 

`read_record()`함수의 경우 많은 레코드가 있으면 성능이 매우 좋지 않다. 시간 복잡도 `O(n)`을 잡아먹기 때문이다. 따라서 데이터베이스의 키값을 효율적으로 찾기위해 색인(`index`)가 등장하게 되었다.

색인의 일반적인 개념은 메타데이터를 유지하는 것이다. 기본 데이터외의 추가적인 데이터로써 질의 성능에 영향을 준다. 이러한 추가적인 데이터는 쓰기 과정에서 오버헤드가 발생한다. 하지만 이는 질의 속도와의 트레이드오프이기에 적절한 색인을 구성하여야 한다.

### 해시 색인(index)

해시 인덱스를 통해 키-값 데이터를 인덱싱하는 예제를 알아본다. 

키-값 저장소는 사전 타입(dictionary type)과 매우 유사하다. 보통 해시 테이블로 구현된다. (해시 충돌시 체이닝 방식 or 개방 주소법 등 활용) 이에 추가적으로 인메모리 데이터 구조를 활용할 수 있다. 

인메모리 구조는 해시 맵을 전부 메모리에 유지하며, 사용 가능한 램에 모든 키가 저장된다는 조건을 기반으로 작동한다.

![](https://velog.velcdn.com/images/cksgodl/post/0e7c5445-e106-4055-be80-f3286f1199e7/image.png)

위의 그림처럼 특정 키에 대한 `byte offset`을 모두 램에 저장하고 이를 통해 고성능 쓰기, 읽기를 제공한다.

하지만 파일에 항상 추가만 한다면 결국 디스크 공간이 부족해진다. 이 상황은 특정 크기의 세그먼트로 로그를 나누면 해결된다. 해시테이블(로그)이 특정 크기에 도달한다면 새로운 세그먼트를 열고 작성하면 된다. 이를 __컴팩션(`compaction`)__이라고 하며 중복된 키 및 제거된 키를 버리고 최신 갱신 값만 유지하는 것을 의미한다.

![](https://velog.velcdn.com/images/cksgodl/post/93f1af27-31e2-4629-8c9e-325d4c96ab64/image.png)

![](https://velog.velcdn.com/images/cksgodl/post/c89d3b06-b616-4cc0-9549-dd30f8e6fd90/image.png)

컴팩션을 통한 세그먼트는 새로운 파일로 생성되며 새로운 세그먼트가 만들어질 동안 이전 요청은 이전 세그먼트를 활용하면 된다. (무중단 배포와 동일) 이러한 세그먼트 방식은 적은 수를 유지하고자 하기에 성능적인 관점에서 이득이다.

하지만 이러한 방식도 키가 너무 많아지는 경우 문제가 된다. 디스크에 해시 맵을 유지할 수 있지만 불행하게도 디스크 상의 해시 맵에 좋은 성능을 기대하기는 어렵다. (무작위 I/O가 많이 필요하며 해시 충돌시 로직을 수행하는데 비용이 비쌈) 또한 해시충돌은 범위 쿼리에 대해 효율적이지 않다. 

다음으로 이러한 제한이 없는 색인 구조를 알아본다.

### SS테이블과 LSM트리

위의 세그먼트 파일형식을 "키"로 정렬해보자. 이는 순차 쓰기를 사용할 수 없게될 것 같지만, 얻는 이점이 더 많다.

키로 정렬된 형식을 __정렬된 문자열 테이블(`Sorted String Table`)__ 또는 짧게 `SS테이블`이라 부른다. 이러한 SS테이블은 해시 색인을 가진 로그 세그먼트보다 몇 가지 큰 장점이 있다.

![](https://velog.velcdn.com/images/cksgodl/post/c997dd28-6f79-4eef-ae6e-eb220e340c15/image.png)

- 키 값으로 정렬되어 `compaction`이 진행된다. 이때 병합정렬(mergesort) 알고리즘을 활용한다.
- 과거 세그멘트에는 중복된 키가 있을 수 있다. 이땐 무조건 최신 세그멘트의 값을 활용한다.
- 아래 그림의 Sparse index(희소 색인)은 요청 범위 내 여러 키-값을 스캔해야 하기 떄문에 해당 레코드들을 블록으로 그룹화하고 디스크에 쓰기 전에 압축한다. 따라서 희소 인메모리 색인의 각 항목은 압축된 블록의 시작을 가리키게 된다.
- 파일에서 특정 키를 찾기 위해 모든 키를 색인할 필요가 없다. 
    ![](https://velog.velcdn.com/images/cksgodl/post/79035df8-bb16-4835-a38b-82e5f5560961/image.png)
    - `handbag`, `handsome` 사이의 오프셋을 스캔하기만 하면 된다.


### SS테이블(Sorted String Table) 생성과 유지

레드 블랙 트리, AVL 트리등을 활용하여 삽입 및 정렬을 수행할 수 있다. 이러한 자료구조를 활용하면 저장소 엔진을 다음과 같이 만들 수 있다.

- 쓰기가 들어오면 자료 구조(레드 블랙 트리)에 맞게 추가한다. -> 이 인메모리 트리는 멤테이블(`memtable`)이라고 한다.
- 멤테이블이 임곗값보다 커지면 SS테이블 파일로 디스크에 기록한다. 새로운 SS테이블 파일은 데이터베이스의 가장 최신 세그먼트가 된다. SS테이블을 기록하는 동안 쓰기는 새로운 멤테이블에 기록한다.
- 읽기 요청이 들어오면 먼저 멤테이블에서 키를 찾고 없으면 디스크 상의 최신 세그먼트에서 찾는다. 없으면 두 번째, 세 번째 세그먼트 등에서 찾는다.
- 가끔 세그먼트 파일을 합치고 덮어 쓰여지거나 삭제된 값을 버리는 작업을 백그라운드에서 실행한다.

이러한 구조는 잘 작동하지만, 데이터베이스 장애가 나면 디스크(인메모리)에 있는 내용은 기록되지 않고 가장 최신 멤테이블에 대한 쓰기가 손실된다. 따라서 쓰기 요청이 올 때 해당 로그를 디스크 상에 유지한다.(이는 정렬되지 않아도 됨으로 빠르다.) 인메모리 테이블을 SS테이블로 디스크에 작성한 후에는 해당 로그를 버린다.

#### SS테이블에서 LSM(Log-Structured-Merge) 트리 만들기

정렬된 파일 병합과 컴팩션 원리를 기반으로 하는 저장소 엔진을 LSM저장소 엔진이라 부른다.(SSTable구조를 응용한 방식)

LSM의 구조는 다음과 같다.

- `Memtable`: 메모리에 상주하는 정렬된 데이터 구조로, 새로운 쓰기 작업을 처리한.
- `SSTable`(Sorted String Table): 디스크에 저장되는 정렬된 불변 파일이다.

메모리의 `Memtable`을 활용하여 새로운 쓰기 작업을 수행하며, `Memtable`이 특정 크기에 도달하면 SSTable로 디스크에 플러시된다.

읽기 작업또한 `Memtable`을 확인한 후 순차적으로 `SSTable`을 검색한다. (블룸 필터 활용)

정리하자면 
- LSM 트리는 SS 테이블의 자료구조를 활용한 자료구조이다.
- LSM 트리의 디스크 컴포넌트가 SS 테이블로 구성되어있다.
- 둘다 세그먼트 병합과 컴팩션 원리를 기반으로 한다.

> Ref, [SS Table 및 LSM Tree](https://www.borntodare.me/71a03b0c-ab44-4e35-862c-c53430749966)

ES, RocksDB, LevelDB, HBase에서도 유사한 알고리즘을 사용한다.

### 성능 최적화

예를 들어 LSM알고리즘은 존재하지 않는 키를 찾는 경우 디스크의 가장 오래된 세그먼트까지 거슬러 올라가야 한다. 따라서 이런 접근을 최적화하기 위해 __블룸 필터(Bloom filter)__를 추가적으로 사용한다.

> 블룸 필터란?
>
> 집합에 특정 요소가 포함되어 있는지 빠르게 확인할 수 있는 확률적 데이터 구조
>
> ![](https://velog.velcdn.com/images/cksgodl/post/bbd0465e-eaea-441a-97c6-c07f74014b54/image.png)

SS테이블을 압축하고 병합하는 순서와 시기를 결정하는 전략이 있지만, 이는 자세하게 알아볼 필요 X

중요한 점은 LSM트리가 백그라운드에서 연쇄적으로 SS테이블을 지속적으로 병합하는 것이다. 따라서 메모리보다 훨씬 큰 데이터에 대한 처리 및 뛰어난 처리량을 제공한다.

### B 트리

거의 대부분의 관계형 데이터베이스에 사용하는 표준 색인 구조이다. (비관계형 데이터베이스에도 많이 사용됨)

이는 4KB(또는 더 크게)의 블록이나 페이지로 나눈다. 각 페이지는 주소나 위치를 이용해 식별할 수 있으며, 이 방식으로 하나의 페이지가 다른 페이지를 참조할 수 있다.(포인터와 비슷하지만 메모리 대신 디스크에 있음)
예를 들면 아래의 그림과 같다.

![](https://velog.velcdn.com/images/cksgodl/post/a5d6535f-250c-40df-bf4f-f56bcc99fab7/image.png)

특정 한 페이지는 B 트리의 루트로 지정되며 범위를 기반하여 주소(reference)를 활용하여 자식 키를 찾는다. (키가 추가되며 루트페이지또한 변경될 수 있다.) 한 페이지에서 하위 페이지를 참조하는 수를 분기 계수라고 한다. 위의 그림에서 분기계수는 `3`이다. 보통 이 분기계수는 수백개에 달한다.

추가와 삭제에 대한 구조 설명은 글로하기 어렵다. 아래의 페이지를 참고하자.

> [B-Tree Visulization](https://www.cs.usfca.edu/~galles/visualization/BTree.html)에서 비트리 구조에 대해 볼 수 있다.

위처럼 B-Tree의 알고리즘은 트리가 균형을 유지하는 것을 보장하며, n개의 키를 가진 B트리는 깊이가 항상 O(log n)이다. 예를 들어 분기 계수 500인 4KB 페이지의 4단계 트리는 256TB까지 저장할 수 있다.

### 신뢰할 수 있는 B 트리 만들기

B 트리의 기본적인 동작은 덮어쓰기다. (주소에 대한 참조는 변하지 않는다고 가정) 디스크의 페이지에 덮어쓰는 일은 실제 하드웨어 동작이다. 더욱이 일부 동작은 두 페이지를 기록하고 여러 페이지를 갱신해야할 수도 있다. 이럴 때 데이터베이스가 고장난다면 색인이 훼손되기에 위험할 수 있다.(고아 페이지가 발생할 수 있다.)

따라서 스스로 복구할 수 있도록 디스크 상에 __쓰기 전 로그(write_ahead log, WAL)(재실행 로그(redo log)라기도 함)__라고 하는 데이터 구조를 추가해 B트리를 구현한다. 쓰기 전 로그는 트리 페이지에 변경된 내용을 적용하기 전에 모든 B트리의 변경사항을 기록하는 추가 전용 파일이다.

![](https://velog.velcdn.com/images/cksgodl/post/c70997ef-3e05-46d4-820f-1764ca452f1c/image.png)

또한 같은 페이지에 대한 갱신 및 조회 작업은 또 다른 문제다. 다중 스레드가 B 트리에 접근한다면 주의 깊게 동시성을 제어해야 한다. 따라서 동시성 제어는 보통 **래치(latch)**로 트리의 데이터 구조를 보호한다. 이는 가벼운 락 구조라고 생각하면 된다. 

### B 트리 최적화

- Copy On Write 
   - 리소스의 변경이 필요할 때 복사를 수행하고, 참조를 변경하는 방식
- 페이지에 전체 키를 저장하지 않고 키를 축약해 보관 -> 하나의 페이지에 키를 더 많이 보관
- 저장소 지역성을 지킨다.
- 트리에 포인터를 추가하여 양쪽 형제페이지에 대한 참조를 추가한다. (B+ Tree?)

![](https://velog.velcdn.com/images/cksgodl/post/c01dfe25-acd2-43f5-9d0c-5e53cdde4922/image.png)

### B 트리와 LSM 트리 비교

실제 필요한 작업부하로 테스트하라. 경험상으로 읽기는 B 트리, 쓰기는 LSM 트리가 빠르다.

### LSM 트리의 장점

* LSM트리는 더 적은 파일을 생성하고, 파편화가 없으며, 컴팩션을 통해 SS테이블을 재기록하기 때문에 오버헤드가 낮다.
* `Memtable`(메모리) 을 먼저 활용하여 키를 저장하기에 상대적으로 쓰기 처리량이 높다. 
* SSD, 하드디스크에 대한 데이터 지역성이 높다.

### LSM 트리의 단점

- 컴팩션 과정이 성능에 영향을 준다.
- 데이터베이스가 점점 커지면 컴팩션 스레드가 해당 대역폭을 커버해야 한다.
- 컴팩션이 유입 쓰기 속도를 따갈 수 없을수도 있다.


### 기타 색인 구조

지금까지는 기본 키 색인 (Primary key)를 설명했다. 하지만 이외에도 보조 색인(Secondary Key)도 존재하며 효율적으로 조인을 수행하거나 질의하는데 사용된다. 

보조 인덱스는 동일한 여러 문서가 존재할 수 있다.

### 색인 안에 값 저장하기

인덱스를 활용하는 방법 중 대표적인 두가지가 있다. 클러스터드 색인(clustered index), 및 비 클러스터드 색인(non clusterd index)가 있다. 각각의 특징을 정리하면 다음과 같다.

| **특징**             | **클러스터드 색인**                             | **비클러스터드 색인**                         |
|----------------------|---------------------------------------------|------------------------------------------|
| **데이터 저장 방식**   | 데이터가 물리적으로 정렬된 상태로 저장됨           | 데이터는 원래 테이블에 그대로 저장되고 색인을 별도 테이블로 유지 |
| **색인 위치**         | 테이블 자체가 색인의 구조를 가짐                  | 색인은 별도의 데이터 구조로 유지됨            |
| **테이블당 생성 가능 개수** | 테이블당 하나만 생성 가능                        | 여러 개 생성 가능                              |
| **검색 속도**         | 색인된 열을 기준으로 매우 빠름                     | 클러스터드 색인보다 느릴 수 있음               |
| **삽입/삭제 성능**    | 정렬 유지로 인해 성능 저하 가능                     | 삽입/삭제가 클러스터드 색인보다 더 빠를 수 있음 |


이 사이의 절충안으로써 커버링 색인(covering index), 포괄열이 있는 색인(index with included column)등이 있다. 

> Ref. [클러스터드 인덱스 (Clustered Index), 넌 클러스터드 인덱스 (Non Clustered Index)](https://velog.io/@sweet_sumin/%ED%81%B4%EB%9F%AC%EC%8A%A4%ED%84%B0%EB%93%9C-%EC%9D%B8%EB%8D%B1%EC%8A%A4-Clustered-Index-%EB%84%8C-%ED%81%B4%EB%9F%AC%EC%8A%A4%ED%84%B0%EB%93%9C-%EC%9D%B8%EB%8D%B1%EC%8A%A4-Non-Clustered-Index)

### 다중 칼럼 색인 

여러개의 값을 색인으로 활용할 수도 있다. 일반적인 유형으로는 **결합 색인(concatenated index)**라고도 하며 **(성, 이름)**의 예와 같이 색인을 저장한다.

위치 정보같은 경우도 이차원 위치를 공간 채움 곡선(space-filling curve)를 활용해 단일 숫자로 변환한 다음 B 트리 색인을 사용하기도 한다. (위도, 경도) -> 단일 숫자 치환

![](https://velog.velcdn.com/images/cksgodl/post/4f6f30d4-d847-41f1-8275-0d7b5c7e5e7a/image.png)

더해 위치뿐만 아니라 (빨강, 초록, 파랑) 및 (날짜, 기온)등의 다차원 색인도 1차원 색인으로 변환할 수 있다. 

### 전문 검색과 퍼지 색인

정확한 값이나 범위에 대한 질의를 알아보았다. 하지만 유사한 키에 대해 검색하기 위한 fuzzy(애매모호한) 색인도 존재한다.

그러나 비슷한 단어를 검색하거나 편집 거리에 대한 결과를 출력하기 위해 퍼지 색인이 필요할 수 있다. 이러한 색인은 여러 키 내 문자에 대한 유한 상태 오토마톤(finite state automaton)으로 트라이(trie)와 유사하고, 이 오토마톤은 레벤슈타인 오토마톤(levelnshtein automaton)으로 변환할 수 있다.

> [하테나의 전문검색 엔진 구성](https://velog.io/@cksgodl/%EB%8C%80%EA%B7%9C%EB%AA%A8-%EC%84%9C%EB%B9%84%EC%8A%A4%EB%A5%BC-%EC%A7%80%ED%83%B1%ED%95%98%EB%8A%94-%EA%B8%B0%EC%88%A0-Chapter-07.-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98-%EC%8B%A4%EC%9A%A9%ED%99%94-87zvydfi) 도 살펴볼만 하다.

### 모든 것을 메모리에 보관

메모리가 점점 싸지고 있다. 따라서 메모리에 전체 데이터를 저장하는 방식도 꽤나 현실적이게 되었고, 이런 이유로 인메모리 데이터베이스가 개발되었다.

`Memcached`와 같은 인메모리 키-값 저장소는 장비가 재시작되면 데이터 손실을 허용하는 캐시 용도로만 사용된다. 하지만 다른 인메모리 데이터베이스는 지속성을 목표로 하며, 해당 방법은 디스크에 변경 사항 로그, 스냅샷을 기록하거나 다른 장비의 인메모리 상태를 복제하는 방법이 있다.

레디스, 멤SQL 등이 인메모리 데이터베이스를 제공한다.

_별도의 이야기로 디스크기반 OS도 인메모리 캐시를 활용한다. 전적으로 인메모리저장소만 활용한다면 디스크에 저장하기 위해 부호화하는 오버헤드를 줄일 수 있어 더 빨라질 뿐이다._

인메모리 데이터베이스는 디스크 기반으로 제공하기 어려운 데이터 구조 (우선순위 큐, 셋)등을 제공한다. 

> 안티캐싱(anti-caching)이란?
> 인 메모리 데이터베이스 아키텍쳐에서 가상 메모리 스왑같은 형식으로 안티 캐싱을 제공한다.
>
> 메모리가 충분하지 않을 때 가장 최근에 사용한 데이터를 메모리에서 디스크로 내보내고 다시 접근할 때 메모리에 적재한다. 전체 메모리 페이지보다 개별 레코드 단위로 작업하기에 OS보다 더효율적으로 메모리를 관리할 수 있다.

## 트랜잭션 처리나 분석?

_책에서 설명하는 트랜잭션 처리는 우리가 아는것과 약간 다르다. 이는 논리 단위 형태로써 읽기 처리 및 쓰기 처리 그룹을 나타낸다._

> 트랜잭션 처리는 ACID(원자성(Atomicity), 일관성(Consistency), 격리성(Isolation), 지속성(Durabillity)) 속성을 가질 필요는 없다. 트랜잭션 처리는 주기적으로 수행되는 일괄 처리 작업과 달리 클라이언트가 지연 시간이 낮은 읽기와 쓰기를 가능하게 한다는 의미이다.

이러한 트랜잭션 처리에 따라 대화식 접근 패턴을 가진 OLTP(`online transaction processing`) 및 데이터 분석을 위한 트랜잭션 처리인 OLAP(`online analytic processing`)으로 나뉘게 된다.

| **구분**   | **OLTP**                               | **OLAP**                              |
|------------|----------------------------------------|---------------------------------------|
| **목적**   | 실시간 트랜잭션 처리                   | 데이터 분석 및 의사결정 지원           |
| **데이터 모델** | 정규화된 구조 (ER 모델)               | 비정규화된 구조 (스타/스노우플레이크 스키마) |
| **작업 유형** | 짧고 빈번한 읽기/쓰기 작업 (INSERT, UPDATE, DELETE) | 복잡한 데이터 조회 및 집계 작업 (SELECT) |
| **성능 요구** | 낮은 지연 시간과 높은 동시성 지원       | 대량 데이터 분석에 최적화              |
| **데이터 볼륨** | 소량의 실시간 데이터                  | 대량의 히스토리 데이터                 |
| **사용자** | 운영 직원, 고객                       | 경영진, 데이터 분석가                  |
| **예시**   | 은행 거래 시스템                      | 금융 데이터 분석 시스템                |
| **기술 스택** | MySQL, PostgreSQL, Oracle Database    | Snowflake, BigQuery, Redshift         |


### 데이터 웨어하우징

대개 기업은 수십가지 트랜잭션 처리 시스템을 가지고있다.(_판매 및 계산, 재고 이력 조사, 경로 계획, 직원 관리 등_) 

OLTP 시스템은 높은 가용성과 낮은 지연 시간의 처리를 기대한다. 따라서 데이터 분석가가 OLTP 데이터베이스에 분석 질의를 실행하는 것을 꺼려한다. 성능 저하 및 비용이 비싸기 때문이다. 

따라서 데이터 웨어하우스라는 개념이 등장한다. __이는 OLTP 작업에 영향을 주지 않고 마음껏 질의할 수 있는 개별 데이터베이스이다.__ 이는 OLTP 시스템에 있는 데이터의 읽기 전용 복사본이다. (하둡) 데이터를 OLTP 데이터베이스에서 (주기적인 덤프 또는 스트림)을 통해 추출하고 웨어하우스에 적재한다. 이런 과정을 ETL(`Extract-Transform-Load`)라고 한다.

![](https://velog.velcdn.com/images/cksgodl/post/5724e609-f9c1-49f8-a3aa-1478702b4d60/image.png)

### OLTP 데이터베이스와 데이터 웨어하우스의 차이점

`SQL`은 일반적으로 분석 질의에 적합하기 떄문에 데이터 웨어하우스 모델은 관계형 모델을 사용한다. 표면적으로 `SQL` 질의를 지원하지만 내부 시스템은 각각의 웨어하우스에 따라 완전히 다르다.

대표적인 예로써는 아파치 하이브, 스파크 SQL, SQL 온 하둡이 있다.

### 분석용 스키마: 별 모양 스키마와 눈꽃송이 모양 스키마

#### 별모양 스키마

데이터 모델은 서비스의 필요에 따라 다양하다. 많은 데이터 웨어하우스는 별 모양 스키마(__star schema)(차원 모델링(dimensional modeling)이라기도 함__)로 알려진 상당히 정형화된 방식을 사용한다.

![](https://velog.velcdn.com/images/cksgodl/post/7a64c793-9d81-4987-b913-15047b4e9433/image.png)

중심에는 사실 테이블(`fact table`)이 있다. 이는 보통 개별 이벤트를 담으며, 이외의 차원 테이블(`dimension table`)을 활용해 누가, 언제, 무엇을, 어떻게, 왜 라는 정보를 담는다.

날짜와 시간도 개별 테이블로 분리하여 공휴일과 같은 추가정보를 부화하할 수 있다.(휴일과 평일의 판매 차이를 질의할 수 있다.)

#### 눈꽃송이 스키마

별 모양 스키마의 변형이며 차원이 하위차원으로 더 세분화 된다. 

![](https://velog.velcdn.com/images/cksgodl/post/fe9948b4-45fc-4ec1-b860-13be849cc72d/image.png)

일반적인 데이터 웨어하우스에서 테이블은 보통 폭이 매우 넓다. 대개 100개이상의 칼럼이며, 자원 테이블 또한 모든 메타데이터를 담기에 그 폭이 매우 넓다. 

### 칼럼 지향 저장소

보통 테이블에 대한 질의에 한번에 4개 이상의 접근은 많이 필요하지 않다. 따라서 이부분의 효율성을 개선할 필요가 있다.

대부분의 `OLTP` 데이터베이스에서 저장소는 로우 지향 방식으로 데이터를 배치한다. 즉 질의를 수행하기 위해 모든 로우를 메모리로 적재한 다음 구문을 해석해 조건을 충족하지 않는 로우를 필터링해야 한다.

이에따라 __칼럼 지향 저장소__가 등장하게 되었으며, 모든 값을 하나의 로우에 함께 저장하지 않는 대신 각 칼럼별로 모든 값을 함께 저장한다. 각 칼럼을 개별 파일에 저장하면 질의에 사용되는 칼럼만 읽고 구분 분석하면 된다.


![](https://velog.velcdn.com/images/cksgodl/post/534613e0-8629-4c8e-abc8-e4fb3d9ad820/image.png)

위 그림은 칼럼 지향 배치의 예제이다. 위의 테이블은 각 로우가 모두 같은 순서인 점에 의존한다. 따라서 23번째 항목의 전체 값을 다시 모으기 위해서는 23번째 인덱스 값이 필요하다.


![](https://velog.velcdn.com/images/cksgodl/post/b105b194-d254-4138-aef0-1493db1c3e5e/image.png)

- 위는 apache druid의 예제로 각 column의 데이터가 분리되어 저장
- 컬럼별로 압축된 비트맵 인덱스를 사용하여 여러 열에 걸쳐 빠른 필터링과 검색을 지원


#### 드루이드의 비트맵 인덱스 쿼리

`Druid`는 검색 인덱스를 추가로 만들어서 문자열 컬럼에 대한 필터링을 용이하게 한다. 쿼리에 대해 각 차원별로 아래와 같은 바이너리 배열이 생성하고, 배열 인덱스 각각은 해당 행이 쿼리 필터 조건에 부합하는지 여부를 나타낸다.

```
San Francisco (City) -> rows [1] -> [1][0][0][0]
Male (Gender) -> rows [1, 2, 3, 4] -> [1][1][1][1]
```

그런 다음 쿼리 필터는 이러한 두 배열에 대해 AND 연산을 실시한다.

```
[1][0][0][0] AND [1][1][1][1] = [1][0][0][0]
```

그 결과, 행 1만 스캔 대상이 된다. 이런 식으로 필터링된 행만 검색함으로써 불필요한 부하를 방지한다. 이러한 바이너리 배열또한 이후 나올 비트맵 압축을 활용한다.

_대형 비트맵 셋에 boolean 연산을 실시하는 이러한 접근방식은 검색 엔진에서 널리 사용되는 예제이다._

### 칼럼 압축

질의에 필요한 칼럼을 디스크에서 읽어 적재하는 작업 외에도 데이터를 압축하면 디스크 처리량을 더 줄일 수 있다.

다양한 압축 방식이 있지만, 그 중 __비트맵 부호화(bitmap encoding)__이 있다.

![](https://velog.velcdn.com/images/cksgodl/post/18f7e39e-06f2-4066-9e1a-e205b02e84b0/image.png)

> 칼럼 지향 저장소와 칼럼 패밀리
>
> 이는 칼럼 지향적이라 부르기엔 오해의 소지가 많다. 각 칼럼 패밀리 안에는 로우 키에 따라 모든 로우와 모든 칼럼을 함께 저장하며 칼럼 압축을 사용하지 않는다. 

### 메모리 대역폭과 벡터화 처리

수백만 로우를 스캔해야 하는 데이터 웨어하우스 질의는 디스크로부터 메모리로 데이터를 가져오는 대역폭이 큰 병목이다. 이뿐만 아니라 메모리와 CPU캐시와의 병목또한 큰 병목이다.

따라서 최신 CPU에서는 __단일 명령 다중 데이터__(`single-instruction-multi-data`, SIMD) 명령을 사용하계끔 신경써야 한다.

또한 CPU주기를 효율적으로 사용하기 위해 데이터를 L1캐시의 크기에 맞게 가져오고, 이 작업을 함수 호출이 없는 __타이트 루프__(`tight loop`)에서 반복한다. (함수는 분기가 필요한 코드보다 타이트 루프를 훨씬 더 빨리 처리한다.) 또한 칼럼 압축을 활용해 L1 캐시에 더 많은 칼럼의 로우를 저장할 수 있다. 

AND와 OR같은 압축된 칼럼 데이터 덩어리를 바로 연산할 수 있게 설계하는 것을 __벡터화 처리(`vectorized processing`)__이라고 한다.

### 칼럼 저장소와 순서 정렬

순서를 도입하기 위해 색인 메커니즘을 사용할 수 있다.

각 컬럼을 독립적으로 정렬할 수는 없다. 한 칼럼의 k번째 항목이 다른 칼럼의 k번째 항목과 같은 로우에 속한다는 것을 알고 있으니 로우를 재구성할 수 있다. 따라서 칼럼별로 저장됐을지라도 데이터는 한번에 전체 로우를 정렬해야 한다.

중요한 점은 정렬 시 키를 최대한 많은 로우를 덜어낼 수 있는 키로 지정해야 한다는 것이다. 이러한 작업을 통해 같은 정렬 칼럼은 연속해서 같은 값이 연속해서 반복되기 떄문에 칼럼 압축에 용이하기 때문이다.

### 칼럼지향 저장소에 쓰기

B트리 사용과 같은 제자리 갱신(update-in-place)접근 방식은 압축된 칼럼에서 불가능하다. 정렬된 테이블의 중간에 있는 로우에 삽입을 원하는 경우 모든 칼럼 파일을 재작성해야 한다.

칼럼지향 저장소에서는 앞부분에서 언급한 `LSM`트리를 활용한다. 모든 쓰기는 먼저 인메모리 저장소로 이동해 정렬된 구조에 추가하고 디스크에 쓸 준비를 한다. 충분한 쓰기를 모으면 디스크 칼럼 파일에 병합하고 대량으로 새로운 파일에 기록한다. 

> `LSM`트리 방식에서 수정은 인메모리(`Memtable`)에 동일한 아이디의 항목의 데이터를 추가하는 방식으로 진행된다. 즉 해당 파일이 디스크에 쓰이기전까지 `READ`는 이전 값을 반환할 수 있다.

쿼리의 경우 메모리와 최근 쓴 파일을 모두 질의한다. 이는 쿼리 옵티마이저에 의해 수행된다. (삽입, 갱신, 삭제 등의 데이터는 후속 질의에 반영된다.)

### 집계: 데이터 큐브와 구체화 뷰

칼럼 저장소는 즉석 분석 질의에 대해 빠르기 때문에 인기가 있다.

간략하게 언급하고 넘어갈 만한 데이터 웨어하우스의 다른 측면으로 __구체화 집계(`materialized aggregate`)__가 있다. 

이는 __구체화 뷰(`materialized view`)__를 활용하여 관계형 모델에서의 가상 뷰와 비슷하다. 해당 뷰의 데이터는 실제 데이터의 복사본이고, 질의를 제공하는 단축키의 역할을 수행한다.

SQL엔진은 원본 데이터를 변경하면 구체화 뷰를 갱신해야 하고, 이는 갱신 비용이 비싸기 때문에 자주 사용하지 않는다. 하지만 데이터 웨어하우스인 `OLAP`데이터 웨어하우스에서 이 전략은 합리적이다.

![](https://velog.velcdn.com/images/cksgodl/post/3617c288-0beb-4984-8d4d-6b8beba54742/image.png)

- imply의 data cube의 예제

데이터 큐브(`data cube`) 또는 `OLAP 큐브`라고 알려진 구체화 뷰는 일반화된 구체화 뷰의 특별 사례이다. 이는 N차원의 테이블을 집계하여 1차원으로 압축 요약할 수 있다. 

구체화 데이터 큐브의 장점은 특정 질의를 효과적으로 미리 계산했기 때문에 해당 질의를 수행할 때 매우 빠르다. 

## 정리

고수준에서 저장소 엔진은 `OLTP`와 `OLAP`라는 큰 두 범주로 나뉜다.

| **구분**   | **OLTP**                               | **OLAP**                              |
|------------|----------------------------------------|---------------------------------------|
| **목적**   | 실시간 트랜잭션 처리                   | 데이터 분석 및 의사결정 지원           |
| **데이터 모델** | 정규화된 구조 (ER 모델)               | 비정규화된 구조 (스타/스노우플레이크 스키마) |
| **작업 유형** | 짧고 빈번한 읽기/쓰기 작업 (INSERT, UPDATE, DELETE) | 복잡한 데이터 조회 및 집계 작업 (SELECT) |
| **성능 요구** | 낮은 지연 시간과 높은 동시성 지원       | 대량 데이터 분석에 최적화              |
| **데이터 볼륨** | 소량의 실시간 데이터                  | 대량의 히스토리 데이터                 |
| **예시**   | 은행 거래 시스템                      | 금융 데이터 분석 시스템                |
| **기술 스택** | MySQL, PostgreSQL, Oracle Database    | Snowflake, BigQuery, Redshift         |


`OLTP`측면에서 두가지 관점을 기억하자.

- 로그 구조화의 관점에서 오래된 파일의 삭제만 허용하고 한 번 쓰여진 파일은 절대 갱신하지 않는다. (LSM트리)
- 제자리 갱신을 제공하지 않으며, 고정 크기 페이지의 셋으로 디스크를 다룬다.







## Ref

- https://metatron-discovery-docs.readthedocs.io/ko/latest/discovery/part01/druid_features.html

